{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/parmb410/repo.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxGURZ40Qsvn",
        "outputId": "ac15fab0-e97e-4534-926c-9be2c33cbf3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'repo'...\n",
            "remote: Enumerating objects: 130, done.\u001b[K\n",
            "remote: Counting objects: 100% (130/130), done.\u001b[K\n",
            "remote: Compressing objects: 100% (103/103), done.\u001b[K\n",
            "remote: Total 130 (delta 40), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (130/130), 47.70 KiB | 2.98 MiB/s, done.\n",
            "Resolving deltas: 100% (40/40), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd repo/diversify"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tx4Fn6wyROjJ",
        "outputId": "107e8a7e-c330-4bfd-874b-e122878304c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/repo/diversify\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4Z8JeHf5RSeH",
        "outputId": "c6be13ca-e204-42f2-b8a8-80b2ff9588b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.21.0+cu124)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.15.3)\n",
            "Collecting numpy==1.23.5 (from -r requirements.txt (line 4))\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.1->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->-r requirements.txt (line 2)) (11.2.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 5)) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 5)) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.1->-r requirements.txt (line 1)) (3.0.2)\n",
            "Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.3.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.5.0 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 2.8.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "db-dtypes 1.4.3 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.23.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "0482184d4f54487e9ee8234677e6fc1c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset\n",
        "!wget https://wjdcloud.blob.core.windows.net/dataset/diversity_emg.zip\n",
        "!unzip diversity_emg.zip && mv emg data/\n",
        "\n",
        "# Create necessary directories\n",
        "!mkdir -p ./data/train_output/act/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LX6NnuejXXlF",
        "outputId": "c529eae1-6258-4ab9-ff94-089df7991245",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-29 21:34:46--  https://wjdcloud.blob.core.windows.net/dataset/diversity_emg.zip\n",
            "Resolving wjdcloud.blob.core.windows.net (wjdcloud.blob.core.windows.net)... 20.60.131.4\n",
            "Connecting to wjdcloud.blob.core.windows.net (wjdcloud.blob.core.windows.net)|20.60.131.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20237244 (19M) [application/zip]\n",
            "Saving to: ‘diversity_emg.zip’\n",
            "\n",
            "diversity_emg.zip   100%[===================>]  19.30M  3.10MB/s    in 7.0s    \n",
            "\n",
            "2025-06-29 21:34:53 (2.76 MB/s) - ‘diversity_emg.zip’ saved [20237244/20237244]\n",
            "\n",
            "Archive:  diversity_emg.zip\n",
            "   creating: emg/\n",
            "   creating: emg/20/\n",
            "  inflating: emg/20/1_raw_data_11-41_22.03.16.txt  \n",
            "  inflating: emg/20/2_raw_data_11-43_22.03.16.txt  \n",
            "   creating: emg/35/\n",
            "  inflating: emg/35/2_raw_data_10-05_13.04.16.txt  \n",
            "  inflating: emg/35/1_raw_data_10-03_13.04.16.txt  \n",
            "   creating: emg/09/\n",
            "  inflating: emg/09/1_raw_data_12-41_23.03.16.txt  \n",
            "  inflating: emg/09/2_raw_data_12-43_23.03.16.txt  \n",
            "   creating: emg/15/\n",
            "  inflating: emg/15/2_raw_data_08-51_13.04.16.txt  \n",
            "  inflating: emg/15/1_raw_data_08-49_13.04.16.txt  \n",
            "   creating: emg/22/\n",
            "  inflating: emg/22/1_raw_data_12-37_28.03.16.txt  \n",
            "  inflating: emg/22/2_raw_data_12-39_28.03.16.txt  \n",
            "   creating: emg/13/\n",
            "  inflating: emg/13/1_raw_data_13-26_21.03.16.txt  \n",
            "  inflating: emg/13/2_raw_data_13-29_21.03.16.txt  \n",
            "   creating: emg/30/\n",
            "  inflating: emg/30/1_raw_data_09-49_21.03.16.txt  \n",
            "  inflating: emg/30/2_raw_data_09-50_21.03.16.txt  \n",
            "   creating: emg/01/\n",
            "  inflating: emg/01/2_raw_data_13-13_22.03.16.txt  \n",
            "  inflating: emg/01/1_raw_data_13-12_22.03.16.txt  \n",
            "   creating: emg/28/\n",
            "  inflating: emg/28/1_raw_data_12-10_15.04.16.txt  \n",
            "  inflating: emg/28/2_raw_data_12-11_15.04.16.txt  \n",
            "  inflating: emg/README.txt          \n",
            "   creating: emg/34/\n",
            "  inflating: emg/34/2_raw_data_10-53_07.04.16.txt  \n",
            "  inflating: emg/34/1_raw_data_10-51_07.04.16.txt  \n",
            "   creating: emg/06/\n",
            "  inflating: emg/06/2_raw_data_10-40_11.04.16.txt  \n",
            "  inflating: emg/06/1_raw_data_10-38_11.04.16.txt  \n",
            "   creating: emg/25/\n",
            "  inflating: emg/25/2_raw_data_14-53_24.04.16.txt  \n",
            "  inflating: emg/25/1_raw_data_14-51_24.04.16.txt  \n",
            "   creating: emg/26/\n",
            "  inflating: emg/26/2_raw_data_10-23_29.03.16.txt  \n",
            "  inflating: emg/26/1_raw_data_10-22_29.03.16.txt  \n",
            "   creating: emg/36/\n",
            "  inflating: emg/36/1_raw_data_13-03_15.04.16.txt  \n",
            "  inflating: emg/36/2_raw_data_13-04_15.04.16.txt  \n",
            "   creating: emg/04/\n",
            "  inflating: emg/04/1_raw_data_18-02_24.04.16.txt  \n",
            "  inflating: emg/04/2_raw_data_18-03_24.04.16.txt  \n",
            "   creating: emg/14/\n",
            "  inflating: emg/14/2_raw_data_09-51_15.04.16.txt  \n",
            "  inflating: emg/14/1_raw_data_09-50_15.04.16.txt  \n",
            "   creating: emg/02/\n",
            "  inflating: emg/02/2_raw_data_14-21_22.03.16.txt  \n",
            "  inflating: emg/02/1_raw_data_14-19_22.03.16.txt  \n",
            "   creating: emg/27/\n",
            "  inflating: emg/27/1_raw_data_12-19_06.04.16.txt  \n",
            "  inflating: emg/27/2_raw_data_12-20_06.04.16.txt  \n",
            "   creating: emg/17/\n",
            "  inflating: emg/17/2_raw_data_11-20_23.03.16.txt  \n",
            "  inflating: emg/17/1_raw_data_11-19_23.03.16.txt  \n",
            "  inflating: emg/emg_x.npy           \n",
            "   creating: emg/03/\n",
            "  inflating: emg/03/1_raw_data_09-32_11.04.16.txt  \n",
            "  inflating: emg/03/2_raw_data_09-34_11.04.16.txt  \n",
            "   creating: emg/31/\n",
            "  inflating: emg/31/2_raw_data_11-16_11.04.16.txt  \n",
            "  inflating: emg/31/1_raw_data_11-15_11.04.16.txt  \n",
            "   creating: emg/11/\n",
            "  inflating: emg/11/1_raw_data_13-11_18.03.16.txt  \n",
            "  inflating: emg/11/2_raw_data_13-13_18.03.16.txt  \n",
            "   creating: emg/21/\n",
            "  inflating: emg/21/2_raw_data_20-30_24.04.16.txt  \n",
            "  inflating: emg/21/1_raw_data_20-28_24.04.16.txt  \n",
            "   creating: emg/10/\n",
            "  inflating: emg/10/1_raw_data_11-08_21.03.16.txt  \n",
            "  inflating: emg/10/2_raw_data_11-10_21.03.16.txt  \n",
            "   creating: emg/05/\n",
            "  inflating: emg/05/2_raw_data_10-29_30.03.16.txt  \n",
            "  inflating: emg/05/1_raw_data_10-28_30.03.16.txt  \n",
            "   creating: emg/19/\n",
            "  inflating: emg/19/1_raw_data_12-10_26.04.16.txt  \n",
            "  inflating: emg/19/2_raw_data_12-11_26.04.16.txt  \n",
            "   creating: emg/08/\n",
            "  inflating: emg/08/1_raw_data_12-14_23.03.16.txt  \n",
            "  inflating: emg/08/2_raw_data_12-16_23.03.16.txt  \n",
            "   creating: emg/12/\n",
            "  inflating: emg/12/2_raw_data_11-36_28.03.16.txt  \n",
            "  inflating: emg/12/1_raw_data_11-35_28.03.16.txt  \n",
            "   creating: emg/16/\n",
            "  inflating: emg/16/2_raw_data_12-14_25.04.16.txt  \n",
            "  inflating: emg/16/1_raw_data_12-12_25.04.16.txt  \n",
            "   creating: emg/24/\n",
            "  inflating: emg/24/1_raw_data_10-16_12.04.16.txt  \n",
            "  inflating: emg/24/2_raw_data_10-17_12.04.16.txt  \n",
            "   creating: emg/33/\n",
            "  inflating: emg/33/2_raw_data_09-50_12.04.16.txt  \n",
            "  inflating: emg/33/1_raw_data_09-49_12.04.16.txt  \n",
            "   creating: emg/07/\n",
            "  inflating: emg/07/2_raw_data_18-50_22.03.16.txt  \n",
            "  inflating: emg/07/1_raw_data_18-48_22.03.16.txt  \n",
            "   creating: emg/32/\n",
            "  inflating: emg/32/2_raw_data_12-06_27.04.16.txt  \n",
            "  inflating: emg/32/1_raw_data_12-04_27.04.16.txt  \n",
            "   creating: emg/18/\n",
            "  inflating: emg/18/1_raw_data_12-35_21.03.16.txt  \n",
            "  inflating: emg/18/2_raw_data_12-37_21.03.16.txt  \n",
            "   creating: emg/23/\n",
            "  inflating: emg/23/1_raw_data_13-18_05.04.16.txt  \n",
            "  inflating: emg/23/2_raw_data_13-19_05.04.16.txt  \n",
            "   creating: emg/29/\n",
            "  inflating: emg/29/2_raw_data_10-18_15.04.16.txt  \n",
            "  inflating: emg/29/1_raw_data_10-17_15.04.16.txt  \n",
            "  inflating: emg/emg_y.npy           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip diversity_emg.zip\n",
        "!mkdir -p ./data/emg\n",
        "!mv emg/* ./data/emg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEk8bPR0XbuD",
        "outputId": "19a25129-3cbb-4e0b-e496-e78f65cfc46c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  diversity_emg.zip\n",
            "   creating: emg/\n",
            "   creating: emg/20/\n",
            "  inflating: emg/20/1_raw_data_11-41_22.03.16.txt  \n",
            "  inflating: emg/20/2_raw_data_11-43_22.03.16.txt  \n",
            "   creating: emg/35/\n",
            "  inflating: emg/35/2_raw_data_10-05_13.04.16.txt  \n",
            "  inflating: emg/35/1_raw_data_10-03_13.04.16.txt  \n",
            "   creating: emg/09/\n",
            "  inflating: emg/09/1_raw_data_12-41_23.03.16.txt  \n",
            "  inflating: emg/09/2_raw_data_12-43_23.03.16.txt  \n",
            "   creating: emg/15/\n",
            "  inflating: emg/15/2_raw_data_08-51_13.04.16.txt  \n",
            "  inflating: emg/15/1_raw_data_08-49_13.04.16.txt  \n",
            "   creating: emg/22/\n",
            "  inflating: emg/22/1_raw_data_12-37_28.03.16.txt  \n",
            "  inflating: emg/22/2_raw_data_12-39_28.03.16.txt  \n",
            "   creating: emg/13/\n",
            "  inflating: emg/13/1_raw_data_13-26_21.03.16.txt  \n",
            "  inflating: emg/13/2_raw_data_13-29_21.03.16.txt  \n",
            "   creating: emg/30/\n",
            "  inflating: emg/30/1_raw_data_09-49_21.03.16.txt  \n",
            "  inflating: emg/30/2_raw_data_09-50_21.03.16.txt  \n",
            "   creating: emg/01/\n",
            "  inflating: emg/01/2_raw_data_13-13_22.03.16.txt  \n",
            "  inflating: emg/01/1_raw_data_13-12_22.03.16.txt  \n",
            "   creating: emg/28/\n",
            "  inflating: emg/28/1_raw_data_12-10_15.04.16.txt  \n",
            "  inflating: emg/28/2_raw_data_12-11_15.04.16.txt  \n",
            "  inflating: emg/README.txt          \n",
            "   creating: emg/34/\n",
            "  inflating: emg/34/2_raw_data_10-53_07.04.16.txt  \n",
            "  inflating: emg/34/1_raw_data_10-51_07.04.16.txt  \n",
            "   creating: emg/06/\n",
            "  inflating: emg/06/2_raw_data_10-40_11.04.16.txt  \n",
            "  inflating: emg/06/1_raw_data_10-38_11.04.16.txt  \n",
            "   creating: emg/25/\n",
            "  inflating: emg/25/2_raw_data_14-53_24.04.16.txt  \n",
            "  inflating: emg/25/1_raw_data_14-51_24.04.16.txt  \n",
            "   creating: emg/26/\n",
            "  inflating: emg/26/2_raw_data_10-23_29.03.16.txt  \n",
            "  inflating: emg/26/1_raw_data_10-22_29.03.16.txt  \n",
            "   creating: emg/36/\n",
            "  inflating: emg/36/1_raw_data_13-03_15.04.16.txt  \n",
            "  inflating: emg/36/2_raw_data_13-04_15.04.16.txt  \n",
            "   creating: emg/04/\n",
            "  inflating: emg/04/1_raw_data_18-02_24.04.16.txt  \n",
            "  inflating: emg/04/2_raw_data_18-03_24.04.16.txt  \n",
            "   creating: emg/14/\n",
            "  inflating: emg/14/2_raw_data_09-51_15.04.16.txt  \n",
            "  inflating: emg/14/1_raw_data_09-50_15.04.16.txt  \n",
            "   creating: emg/02/\n",
            "  inflating: emg/02/2_raw_data_14-21_22.03.16.txt  \n",
            "  inflating: emg/02/1_raw_data_14-19_22.03.16.txt  \n",
            "   creating: emg/27/\n",
            "  inflating: emg/27/1_raw_data_12-19_06.04.16.txt  \n",
            "  inflating: emg/27/2_raw_data_12-20_06.04.16.txt  \n",
            "   creating: emg/17/\n",
            "  inflating: emg/17/2_raw_data_11-20_23.03.16.txt  \n",
            "  inflating: emg/17/1_raw_data_11-19_23.03.16.txt  \n",
            "  inflating: emg/emg_x.npy           \n",
            "   creating: emg/03/\n",
            "  inflating: emg/03/1_raw_data_09-32_11.04.16.txt  \n",
            "  inflating: emg/03/2_raw_data_09-34_11.04.16.txt  \n",
            "   creating: emg/31/\n",
            "  inflating: emg/31/2_raw_data_11-16_11.04.16.txt  \n",
            "  inflating: emg/31/1_raw_data_11-15_11.04.16.txt  \n",
            "   creating: emg/11/\n",
            "  inflating: emg/11/1_raw_data_13-11_18.03.16.txt  \n",
            "  inflating: emg/11/2_raw_data_13-13_18.03.16.txt  \n",
            "   creating: emg/21/\n",
            "  inflating: emg/21/2_raw_data_20-30_24.04.16.txt  \n",
            "  inflating: emg/21/1_raw_data_20-28_24.04.16.txt  \n",
            "   creating: emg/10/\n",
            "  inflating: emg/10/1_raw_data_11-08_21.03.16.txt  \n",
            "  inflating: emg/10/2_raw_data_11-10_21.03.16.txt  \n",
            "   creating: emg/05/\n",
            "  inflating: emg/05/2_raw_data_10-29_30.03.16.txt  \n",
            "  inflating: emg/05/1_raw_data_10-28_30.03.16.txt  \n",
            "   creating: emg/19/\n",
            "  inflating: emg/19/1_raw_data_12-10_26.04.16.txt  \n",
            "  inflating: emg/19/2_raw_data_12-11_26.04.16.txt  \n",
            "   creating: emg/08/\n",
            "  inflating: emg/08/1_raw_data_12-14_23.03.16.txt  \n",
            "  inflating: emg/08/2_raw_data_12-16_23.03.16.txt  \n",
            "   creating: emg/12/\n",
            "  inflating: emg/12/2_raw_data_11-36_28.03.16.txt  \n",
            "  inflating: emg/12/1_raw_data_11-35_28.03.16.txt  \n",
            "   creating: emg/16/\n",
            "  inflating: emg/16/2_raw_data_12-14_25.04.16.txt  \n",
            "  inflating: emg/16/1_raw_data_12-12_25.04.16.txt  \n",
            "   creating: emg/24/\n",
            "  inflating: emg/24/1_raw_data_10-16_12.04.16.txt  \n",
            "  inflating: emg/24/2_raw_data_10-17_12.04.16.txt  \n",
            "   creating: emg/33/\n",
            "  inflating: emg/33/2_raw_data_09-50_12.04.16.txt  \n",
            "  inflating: emg/33/1_raw_data_09-49_12.04.16.txt  \n",
            "   creating: emg/07/\n",
            "  inflating: emg/07/2_raw_data_18-50_22.03.16.txt  \n",
            "  inflating: emg/07/1_raw_data_18-48_22.03.16.txt  \n",
            "   creating: emg/32/\n",
            "  inflating: emg/32/2_raw_data_12-06_27.04.16.txt  \n",
            "  inflating: emg/32/1_raw_data_12-04_27.04.16.txt  \n",
            "   creating: emg/18/\n",
            "  inflating: emg/18/1_raw_data_12-35_21.03.16.txt  \n",
            "  inflating: emg/18/2_raw_data_12-37_21.03.16.txt  \n",
            "   creating: emg/23/\n",
            "  inflating: emg/23/1_raw_data_13-18_05.04.16.txt  \n",
            "  inflating: emg/23/2_raw_data_13-19_05.04.16.txt  \n",
            "   creating: emg/29/\n",
            "  inflating: emg/29/2_raw_data_10-18_15.04.16.txt  \n",
            "  inflating: emg/29/1_raw_data_10-17_15.04.16.txt  \n",
            "  inflating: emg/emg_y.npy           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --data_dir ./data/ --task cross_people --test_envs 0 --dataset emg --algorithm diversify --latent_domain_num 10 --alpha1 1.0 --alpha 1.0 --lam 0.0 --local_epoch 3 --max_epoch 10 --lr 0.01 --output ./data/train_output/act/cross_people-emg-Diversify-0-10-1-1-0-3-50-0.01"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5IVTwcPXoU-",
        "outputId": "af859d40-5ff2-4b73-b01f-942efb468f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment:\n",
            "\tPython: 3.11.13\n",
            "\tPyTorch: 2.6.0+cu124\n",
            "\tTorchvision: 0.21.0+cu124\n",
            "\tCUDA: 12.4\n",
            "\tCUDNN: 90100\n",
            "\tNumPy: 1.23.5\n",
            "\tPIL: 11.2.1\n",
            "==========================================\n",
            "algorithm:diversify\n",
            "alpha:1.0\n",
            "alpha1:1.0\n",
            "batch_size:32\n",
            "beta1:0.5\n",
            "bottleneck:256\n",
            "checkpoint_freq:100\n",
            "classifier:linear\n",
            "data_file:\n",
            "dataset:emg\n",
            "data_dir:./data/\n",
            "dis_hidden:256\n",
            "gpu_id:0\n",
            "layer:bn\n",
            "lam:0.0\n",
            "latent_domain_num:10\n",
            "local_epoch:3\n",
            "lr:0.01\n",
            "lr_decay1:1.0\n",
            "lr_decay2:1.0\n",
            "max_epoch:10\n",
            "model_size:median\n",
            "N_WORKERS:4\n",
            "old:False\n",
            "seed:0\n",
            "task:cross_people\n",
            "test_envs:[0]\n",
            "output:./data/train_output/act/cross_people-emg-Diversify-0-10-1-1-0-3-50-0.01\n",
            "weight_decay:0.0005\n",
            "steps_per_epoch:10000000000\n",
            "select_position:{'emg': [0]}\n",
            "select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}\n",
            "hz_list:{'emg': 1000}\n",
            "act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}\n",
            "num_classes:6\n",
            "input_shape:(8, 1, 200)\n",
            "grid_size:10\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[INFO] Optimal K determined as 2 (Silhouette Score: 0.1848)\n",
            "Using automated latent_domain_num (K): 2\n",
            "\n",
            "========ROUND 0========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "0                0.4167747200    \n",
            "1                1.2907798290    \n",
            "2                0.2996059656    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.2820461988     1.2815370560     0.0005091093    \n",
            "1                1.4289937019     1.4284850359     0.0005086873    \n",
            "2                1.3433582783     1.3427700996     0.0005881707    \n",
            "Counter({0: 1257, 4: 746, 2: 629, 3: 558, 8: 357, 5: 170, 7: 141, 1: 110, 6: 102, 9: 74})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                1.5060799122     1.2654029131     2.7714829445     0.8163610039     0.7990338164     0.6555164319     2.5534789562    \n",
            "1                1.1508845091     0.9844270349     2.1353116035     0.8373552124     0.8347826087     0.6942488263     6.0195915699    \n",
            "2                0.7708566189     1.3302243948     2.1010808945     0.8373552124     0.8202898551     0.6596244131     8.4783630371    \n",
            "\n",
            "========ROUND 1========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.9425591230    \n",
            "1                1.3578844070    \n",
            "2                1.3589507341    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.7469499111     0.5871246457     1.1598253250    \n",
            "1                1.9232766628     1.3169360161     0.6063406467    \n",
            "2                2.5644993782     1.2454888821     1.3190104961    \n",
            "Counter({4: 823, 0: 727, 2: 562, 3: 480, 8: 411, 5: 316, 6: 274, 7: 259, 1: 197, 9: 95})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.7378245592     1.7884378433     2.5262622833     0.8378378378     0.8125603865     0.6555164319     2.7430570126    \n",
            "1                0.9905813932     0.8837729692     1.8743543625     0.8354247104     0.7980676329     0.6690140845     5.2200129032    \n",
            "2                0.4801716506     1.1560487747     1.6362204552     0.8518339768     0.8289855072     0.7001173709     7.6590182781    \n",
            "\n",
            "========ROUND 2========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.6916038990    \n",
            "1                0.7290747762    \n",
            "2                0.7362535000    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                2.5386652946     1.2712861300     1.2673791647    \n",
            "1                2.8187155724     1.8087263107     1.0099893808    \n",
            "2                1.7478969097     0.8714680672     0.8764287829    \n",
            "Counter({4: 788, 0: 612, 2: 507, 8: 496, 6: 424, 3: 377, 5: 338, 7: 284, 1: 220, 9: 98})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.9403933883     1.3123526573     2.2527461052     0.8407335907     0.7903381643     0.6672535211     2.5312929153    \n",
            "1                0.4713313878     1.6684825420     2.1398139000     0.6054536680     0.5913043478     0.4671361502     5.0195548534    \n",
            "2                1.4052163363     1.3794258833     2.7846422195     0.8689671815     0.8318840580     0.7136150235     7.5044238567    \n",
            "\n",
            "========ROUND 3========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                1.2289783955    \n",
            "1                1.3903218508    \n",
            "2                0.9632446170    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.6028957367     0.9023995399     0.7004962564    \n",
            "1                1.6528592110     0.8680505753     0.7848086357    \n",
            "2                2.3348031044     1.4537234306     0.8810797334    \n",
            "Counter({4: 814, 0: 525, 8: 492, 2: 471, 6: 414, 5: 404, 3: 378, 7: 285, 1: 278, 9: 83})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.8366259336     1.5948793888     2.4315052032     0.8713803089     0.8318840580     0.6619718310     2.4701201916    \n",
            "1                0.4742449522     1.7956969738     2.2699418068     0.8363899614     0.7903381643     0.6754694836     5.2792305946    \n",
            "2                0.9819246531     1.1613137722     2.1432385445     0.8540057915     0.7932367150     0.6866197183     8.0226621628    \n",
            "\n",
            "========ROUND 4========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.6448153853    \n",
            "1                1.6847691536    \n",
            "2                1.1916339397    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.5011696815     0.5971113443     0.9040583968    \n",
            "1                2.2203326225     0.9239770174     1.2963556051    \n",
            "2                2.3237276077     1.2566075325     1.0671201944    \n",
            "Counter({4: 897, 2: 513, 8: 513, 0: 417, 6: 413, 5: 411, 3: 364, 1: 274, 7: 223, 9: 119})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.3441389501     1.5442198515     1.8883588314     0.8735521236     0.8212560386     0.7153755869     3.1786663532    \n",
            "1                1.0508661270     1.4140281677     2.4648942947     0.8928571429     0.8396135266     0.6836854460     5.6755056381    \n",
            "2                0.6849731207     1.6377537251     2.3227267265     0.8544884170     0.8173913043     0.6602112676     8.2054119110    \n",
            "\n",
            "========ROUND 5========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                1.1480506659    \n",
            "1                1.3267141581    \n",
            "2                1.1921622753    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.1903383732     0.8473947644     0.3429435790    \n",
            "1                1.5541827679     1.1530579329     0.4011248350    \n",
            "2                1.5931842327     0.9932559729     0.5999282598    \n",
            "Counter({4: 931, 2: 517, 8: 502, 6: 451, 0: 422, 5: 419, 3: 303, 1: 269, 7: 223, 9: 107})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.5947170854     1.6009005308     2.1956176758     0.8465250965     0.8144927536     0.6578638498     2.5630214214    \n",
            "1                0.5732734799     1.4044616222     1.9777350426     0.7208011583     0.6560386473     0.5187793427     5.1675662994    \n",
            "2                0.2347580642     1.6739361286     1.9086941481     0.8822393822     0.8309178744     0.6854460094     7.7442700863    \n",
            "\n",
            "========ROUND 6========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.4592481852    \n",
            "1                0.4932053685    \n",
            "2                1.3839465380    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                2.3230149746     0.7256602645     1.5973547697    \n",
            "1                1.0323109627     0.8576987386     0.1746121645    \n",
            "2                2.2465155125     1.1477116346     1.0988038778    \n",
            "Counter({4: 938, 8: 516, 2: 509, 5: 457, 0: 403, 6: 361, 3: 324, 1: 296, 7: 186, 9: 154})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.8842609525     2.5418000221     3.4260609150     0.8467664093     0.7845410628     0.6508215962     2.5627248287    \n",
            "1                0.5854380727     1.5418308973     2.1272690296     0.8192567568     0.7536231884     0.6173708920     5.1564967632    \n",
            "2                0.4428246319     2.0542957783     2.4971203804     0.8807915058     0.8057971014     0.6613849765     8.0699627399    \n",
            "\n",
            "========ROUND 7========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.8430664539    \n",
            "1                1.1169096231    \n",
            "2                0.6293269396    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.6239733696     1.2372039557     0.3867694139    \n",
            "1                1.9373557568     1.1184298992     0.8189259171    \n",
            "2                1.6437077522     0.9893239737     0.6543837190    \n",
            "Counter({4: 960, 5: 491, 2: 470, 8: 442, 6: 402, 0: 372, 1: 325, 3: 313, 7: 188, 9: 181})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.2536848783     1.6142954826     1.8679803610     0.8619691120     0.8241545894     0.6449530516     2.9868624210    \n",
            "1                0.4393309355     1.6035553217     2.0428862572     0.8745173745     0.8260869565     0.6613849765     5.5885615349    \n",
            "2                0.2256442159     1.2379714251     1.4636156559     0.8774131274     0.8183574879     0.6637323944     8.0734882355    \n",
            "\n",
            "========ROUND 8========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                1.5597141981    \n",
            "1                0.9466350079    \n",
            "2                0.7590601444    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.9575295448     1.5240089893     0.4335205555    \n",
            "1                1.7306249142     1.0819882154     0.6486366987    \n",
            "2                1.6579663754     1.3798682690     0.2780980766    \n",
            "Counter({4: 940, 5: 479, 2: 439, 8: 427, 6: 372, 1: 371, 0: 345, 3: 331, 9: 239, 7: 201})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.7371405959     2.4773995876     3.2145402431     0.9054054054     0.8367149758     0.6602112676     2.4619903564    \n",
            "1                0.5065201521     1.4516180754     1.9581382275     0.8776544402     0.8125603865     0.6907276995     4.9431841373    \n",
            "2                0.5100495815     1.6154057980     2.1254553795     0.8822393822     0.8115942029     0.6572769953     7.4178290367    \n",
            "\n",
            "========ROUND 9========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                1.8546010256    \n",
            "1                1.4753754139    \n",
            "2                1.4455049038    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                2.3872256279     1.2878960371     1.0993294716    \n",
            "1                2.0239715576     1.2781558037     0.7458157539    \n",
            "2                1.3282757998     1.0297986269     0.2984771430    \n",
            "Counter({4: 923, 5: 466, 2: 449, 8: 415, 6: 404, 1: 375, 9: 330, 0: 299, 3: 298, 7: 185})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.1952542067     1.4833236933     1.6785778999     0.8701737452     0.7971014493     0.6995305164     2.4609239101    \n",
            "1                0.3329290152     1.4905376434     1.8234666586     0.9051640927     0.8357487923     0.6807511737     4.9291112423    \n",
            "2                0.4654983580     1.6317492723     2.0972476006     0.8552123552     0.7951690821     0.6343896714     7.8937664032    \n",
            "Target acc: 0.6837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --data_dir ./data/ --task cross_people --test_envs 1 --dataset emg --algorithm diversify --latent_domain_num 2 --alpha1 0.1 --alpha 10.0 --lam 0.0 --local_epoch 10 --max_epoch 10 --lr 0.01 --output ./data/train_output/act/cross_people-emg-Diversify-1-2-0.1-10-0-10-15-0.01"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjNT9qqNXqiO",
        "outputId": "a821f7fe-d1ef-42db-e2f2-0b127c7ce32b",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment:\n",
            "\tPython: 3.11.13\n",
            "\tPyTorch: 2.6.0+cu124\n",
            "\tTorchvision: 0.21.0+cu124\n",
            "\tCUDA: 12.4\n",
            "\tCUDNN: 90100\n",
            "\tNumPy: 1.23.5\n",
            "\tPIL: 11.2.1\n",
            "==========================================\n",
            "algorithm:diversify\n",
            "alpha:10.0\n",
            "alpha1:0.1\n",
            "batch_size:32\n",
            "beta1:0.5\n",
            "bottleneck:256\n",
            "checkpoint_freq:100\n",
            "classifier:linear\n",
            "data_file:\n",
            "dataset:emg\n",
            "data_dir:./data/\n",
            "dis_hidden:256\n",
            "gpu_id:0\n",
            "layer:bn\n",
            "lam:0.0\n",
            "latent_domain_num:2\n",
            "local_epoch:10\n",
            "lr:0.01\n",
            "lr_decay1:1.0\n",
            "lr_decay2:1.0\n",
            "max_epoch:10\n",
            "model_size:median\n",
            "N_WORKERS:4\n",
            "old:False\n",
            "seed:0\n",
            "task:cross_people\n",
            "test_envs:[1]\n",
            "output:./data/train_output/act/cross_people-emg-Diversify-1-2-0.1-10-0-10-15-0.01\n",
            "weight_decay:0.0005\n",
            "steps_per_epoch:10000000000\n",
            "select_position:{'emg': [0]}\n",
            "select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}\n",
            "hz_list:{'emg': 1000}\n",
            "act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}\n",
            "num_classes:6\n",
            "input_shape:(8, 1, 200)\n",
            "grid_size:10\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[INFO] Optimal K determined as 2 (Silhouette Score: 0.1991)\n",
            "Using automated latent_domain_num (K): 2\n",
            "\n",
            "========ROUND 0========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "0                0.5183101296    \n",
            "1                0.6726552844    \n",
            "2                0.4059629738    \n",
            "3                0.9661216736    \n",
            "4                0.4619013369    \n",
            "5                0.5881627798    \n",
            "6                0.8769107461    \n",
            "7                0.4046888649    \n",
            "8                0.4006103277    \n",
            "9                0.1763232350    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.7451840639     0.7447569370     0.0004271149    \n",
            "1                1.8886405230     1.8882948160     0.0003456692    \n",
            "2                1.5983175039     1.5980430841     0.0002744533    \n",
            "3                0.8711789846     0.8707382083     0.0004407475    \n",
            "4                1.0950951576     1.0947197676     0.0003754316    \n",
            "5                2.1585357189     2.1581523418     0.0003833972    \n",
            "6                1.6136000156     1.6132262945     0.0003736884    \n",
            "7                1.0792328119     1.0789436102     0.0002892075    \n",
            "8                0.9883759618     0.9879713058     0.0004046727    \n",
            "9                1.8329719305     1.8326230049     0.0003488828    \n",
            "Counter({1: 2477, 0: 1579})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.7680215836     0.5958978534     1.3639194965     0.6706114398     0.6604146101     0.6152149945     2.4450323582    \n",
            "1                1.1885296106     0.3533015251     1.5418311357     0.7423570020     0.6910167818     0.6945975744     5.5474040508    \n",
            "2                1.1414005756     0.4610913992     1.6024919748     0.7798323471     0.7680157947     0.7557883131     8.0136501789    \n",
            "3                1.2704226971     0.8211746812     2.0915973186     0.7948717949     0.7690029615     0.7381477398     10.4249994755   \n",
            "4                0.2242268920     0.4287023246     0.6529291868     0.8500986193     0.8262586377     0.8340683572     12.8424043655   \n",
            "5                0.4092768133     0.3339911401     0.7432679534     0.7640532544     0.7443237907     0.7783902977     15.2891952991   \n",
            "6                0.5247431397     0.5465283990     1.0712715387     0.7914201183     0.7492596249     0.7690187431     18.2287333012   \n",
            "7                0.9193317294     0.2491922975     1.1685240269     0.8500986193     0.8272458045     0.8153252481     20.6923182011   \n",
            "8                0.4862703085     0.2785318196     0.7648020983     0.8693293886     0.8568608095     0.8461962514     23.1280558109   \n",
            "9                0.4173873365     0.4840310514     0.9014183879     0.8333333333     0.8065153011     0.8009922822     25.5537326336   \n",
            "\n",
            "========ROUND 1========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.6040463448    \n",
            "1                0.7432925105    \n",
            "2                0.7934453487    \n",
            "3                0.8356887698    \n",
            "4                1.1130703688    \n",
            "5                1.0004134178    \n",
            "6                0.7976946831    \n",
            "7                0.4574145079    \n",
            "8                1.0119452477    \n",
            "9                0.6590575576    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.4015498161     1.3004318476     0.1011179909    \n",
            "1                1.0615078211     0.8963413835     0.1651664525    \n",
            "2                1.3620954752     1.0777281523     0.2843673229    \n",
            "3                1.3115326166     1.2241619825     0.0873706043    \n",
            "4                1.4634164572     1.2108279467     0.2525885403    \n",
            "5                1.5187017918     1.3645914793     0.1541102827    \n",
            "6                1.2125881910     1.1295603514     0.0830278024    \n",
            "7                1.3704042435     1.2727273703     0.0976769105    \n",
            "8                1.6291928291     1.4713789225     0.1578138620    \n",
            "9                1.3520433903     1.0426983833     0.3093450069    \n",
            "Counter({1: 2513, 0: 1543})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                1.0781656504     0.4180058539     1.4961714745     0.8345660750     0.7887462981     0.7855567806     2.5228369236    \n",
            "1                0.5746487975     0.2463714927     0.8210203052     0.8508382643     0.8065153011     0.8638368247     5.4921264648    \n",
            "2                0.3759469986     0.4267185032     0.8026654720     0.8981755424     0.8321816387     0.8351708931     7.9681398869    \n",
            "3                0.6677084565     0.3933780193     1.0610864162     0.8774654832     0.8272458045     0.8649393605     10.4145114422   \n",
            "4                0.4825231731     0.1561483890     0.6386715770     0.8759861933     0.8223099704     0.8296582139     12.8356020451   \n",
            "5                0.3031188548     0.2676936090     0.5708124638     0.8560157791     0.8114511352     0.8004410143     15.5542871952   \n",
            "6                0.3595094383     0.3701477051     0.7296571732     0.9035996055     0.8400789733     0.8439911797     18.2936511040   \n",
            "7                0.8024587035     0.5917647481     1.3942234516     0.8424556213     0.7778874630     0.7508269019     20.7356009483   \n",
            "8                0.4595082700     0.5767260194     1.0362342596     0.8747534517     0.8104639684     0.8230429989     23.1565353870   \n",
            "9                0.7296679616     0.3078009784     1.0374689102     0.8907790927     0.8341559724     0.8434399118     25.5666728020   \n",
            "\n",
            "========ROUND 2========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.6328488588    \n",
            "1                0.6419944763    \n",
            "2                1.0862957239    \n",
            "3                0.5840898156    \n",
            "4                0.5905058980    \n",
            "5                0.2382340282    \n",
            "6                0.4549266994    \n",
            "7                0.6804814339    \n",
            "8                0.4543257058    \n",
            "9                0.3401109874    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.9035574198     0.8712558150     0.0323015898    \n",
            "1                1.4471762180     1.3447831869     0.1023930833    \n",
            "2                1.4530296326     1.3526744843     0.1003550887    \n",
            "3                1.6035057306     1.4606968164     0.1428089142    \n",
            "4                1.4227919579     1.3701974154     0.0525945872    \n",
            "5                1.3304917812     1.2731277943     0.0573640428    \n",
            "6                0.8913312554     0.7513776422     0.1399535984    \n",
            "7                1.4869483709     1.4496736526     0.0372746922    \n",
            "8                1.4431158304     1.3898271322     0.0532886535    \n",
            "9                1.2852159739     1.2503527403     0.0348632857    \n",
            "Counter({1: 2497, 0: 1559})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.8184586167     1.1930180788     2.0114767551     0.8513313609     0.7798617966     0.7497243660     2.7950985432    \n",
            "1                0.8674276471     0.4734862745     1.3409138918     0.8459072978     0.7581441264     0.7690187431     5.4780333042    \n",
            "2                0.3448612690     0.8785790801     1.2234404087     0.8570019724     0.7926949654     0.7954796031     7.9276049137    \n",
            "3                0.9364020824     0.3049823940     1.2413845062     0.8841222880     0.8015794669     0.8269018743     10.3456060886   \n",
            "4                0.3922542036     0.4395921230     0.8318463564     0.9001479290     0.8193484699     0.8065049614     12.8504421711   \n",
            "5                0.4779634178     0.3811824620     0.8591458797     0.8801775148     0.8124383021     0.8103638368     15.9241278172   \n",
            "6                0.4655400217     0.2762750685     0.7418150902     0.8774654832     0.8144126357     0.8423373760     18.3948988914   \n",
            "7                0.7611384392     0.1877260953     0.9488645196     0.8979289941     0.8272458045     0.8296582139     20.8099756241   \n",
            "8                0.5673645735     0.4749649465     1.0423295498     0.8942307692     0.8065153011     0.8246968026     23.2393472195   \n",
            "9                0.9595620036     0.8654296994     1.8249917030     0.6878698225     0.6396841066     0.6306504961     25.6868195534   \n",
            "\n",
            "========ROUND 3========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.7419846654    \n",
            "1                0.5364767313    \n",
            "2                0.4899712801    \n",
            "3                0.2794806659    \n",
            "4                0.5059097409    \n",
            "5                0.3076401055    \n",
            "6                0.4554384947    \n",
            "7                0.2559453845    \n",
            "8                0.5797817707    \n",
            "9                0.4896964729    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.3621238470     1.3264067173     0.0357171558    \n",
            "1                1.5209683180     1.4057513475     0.1152169332    \n",
            "2                1.2606710196     1.1331858635     0.1274851710    \n",
            "3                1.2558938265     1.2020069361     0.0538868345    \n",
            "4                1.0203404427     0.9905419946     0.0297984798    \n",
            "5                0.8259127140     0.7631783485     0.0627343953    \n",
            "6                0.9207095504     0.8701679707     0.0505415685    \n",
            "7                1.0127829313     0.9233753085     0.0894075930    \n",
            "8                1.7780487537     1.2675999403     0.5104488730    \n",
            "9                1.0036333799     0.9464154840     0.0572178811    \n",
            "Counter({1: 2536, 0: 1520})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.5243483186     0.3421784937     0.8665268421     0.8658777120     0.7778874630     0.7866593164     3.0040712357    \n",
            "1                0.5618390441     0.5015897155     1.0634287596     0.8700690335     0.7818361303     0.7750826902     5.4084823132    \n",
            "2                0.1778679043     0.2527748048     0.4306427240     0.8939842209     0.8035538006     0.8070562293     7.8076739311    \n",
            "3                0.4333964884     0.4437904060     0.8771868944     0.8385108481     0.7344521224     0.7673649394     10.2268829346   \n",
            "4                0.4470683634     0.4503645897     0.8974329233     0.8782051282     0.7561697927     0.7844542448     12.6876616478   \n",
            "5                0.4029241502     0.3303135335     0.7332376838     0.8964497041     0.7917077986     0.8164277839     15.6276476383   \n",
            "6                0.4824351072     0.4101799726     0.8926150799     0.9085305720     0.8223099704     0.8208379272     18.0821902752   \n",
            "7                0.8839324117     0.8673732281     1.7513055801     0.7152366864     0.6229022705     0.6394707828     20.5258643627   \n",
            "8                0.3902671635     0.5868991613     0.9771662951     0.8762327416     0.7946692991     0.8087100331     23.0304937363   \n",
            "9                0.5684248209     0.4954921901     1.0639170408     0.8047337278     0.7028627838     0.7447629548     25.7317578793   \n",
            "\n",
            "========ROUND 4========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.2585098445    \n",
            "1                0.3626561165    \n",
            "2                1.4754630327    \n",
            "3                1.0912181139    \n",
            "4                0.4775272310    \n",
            "5                0.2859220207    \n",
            "6                0.4641660750    \n",
            "7                0.1415834427    \n",
            "8                0.6777834296    \n",
            "9                0.8661685586    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.6861158609     1.6293240786     0.0567918085    \n",
            "1                1.4909256697     1.4659863710     0.0249393135    \n",
            "2                1.4544873238     1.3947349787     0.0597524010    \n",
            "3                0.9541616440     0.7359829545     0.2181787044    \n",
            "4                1.2062437534     1.0030938387     0.2031499147    \n",
            "5                0.8929376602     0.8857576847     0.0071799774    \n",
            "6                1.0282454491     0.9164314866     0.1118140221    \n",
            "7                1.7887827158     1.5933680534     0.1954146773    \n",
            "8                1.1065630913     0.9397127032     0.1668503731    \n",
            "9                1.4369087219     1.2566270828     0.1802816540    \n",
            "Counter({1: 2542, 0: 1514})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.6586385369     0.3081117570     0.9667502642     0.8784516765     0.7808489635     0.7971334068     2.8495402336    \n",
            "1                0.4814653695     0.2548023760     0.7362677455     0.9080374753     0.8173741362     0.8087100331     5.3469107151    \n",
            "2                0.6343711019     0.8730809093     1.5074520111     0.8375246548     0.7453109576     0.7557883131     7.7978320122    \n",
            "3                0.4239521921     0.3509744108     0.7749266028     0.9008875740     0.8015794669     0.7761852260     10.2604506016   \n",
            "4                0.6913289428     0.5493229032     1.2406518459     0.8259368836     0.7226061204     0.7089305402     13.1151766777   \n",
            "5                0.7387693524     0.5562102199     1.2949795723     0.8281558185     0.7364264561     0.7304299890     15.7455158234   \n",
            "6                0.3305732906     0.6995024681     1.0300757885     0.8202662722     0.7107601185     0.7050716648     18.2098946571   \n",
            "7                1.0070902109     0.3280794322     1.3351696730     0.8964497041     0.7897334650     0.8070562293     20.6442101002   \n",
            "8                0.4516749382     0.4688887894     0.9205636978     0.8698224852     0.7759131293     0.7734288864     23.0866723061   \n",
            "9                1.2178460360     0.7631892562     1.9810352325     0.7793392505     0.7008884501     0.6730981257     26.1343779564   \n",
            "\n",
            "========ROUND 5========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.3964658082    \n",
            "1                0.2003613114    \n",
            "2                0.1901406646    \n",
            "3                0.5283839703    \n",
            "4                0.5964075923    \n",
            "5                0.2776146829    \n",
            "6                0.1739791632    \n",
            "7                0.3443283141    \n",
            "8                0.4649478197    \n",
            "9                0.6194401979    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                2.1331584454     2.0148949623     0.1182635427    \n",
            "1                1.2036693096     1.1244035959     0.0792656839    \n",
            "2                0.7398621440     0.7239517570     0.0159103815    \n",
            "3                1.1154325008     1.1112222672     0.0042102053    \n",
            "4                0.8685358167     0.8093304634     0.0592053719    \n",
            "5                0.9254483581     0.8346289992     0.0908193588    \n",
            "6                1.0277802944     1.0101059675     0.0176743232    \n",
            "7                0.8126631379     0.8011910319     0.0114721125    \n",
            "8                1.0848804712     1.0235422850     0.0613381453    \n",
            "9                1.1427404881     0.8785647750     0.2641757429    \n",
            "Counter({1: 2546, 0: 1510})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.2146329433     0.4808857739     0.6955187321     0.8604536489     0.7808489635     0.7568908490     2.6075537205    \n",
            "1                0.9265267849     0.3422468603     1.2687736750     0.9077909270     0.8005923001     0.7866593164     5.0359082222    \n",
            "2                0.4433449805     0.5399819016     0.9833269119     0.9006410256     0.7857847976     0.7794928335     7.4900183678    \n",
            "3                0.5582836270     0.6222059131     1.1804895401     0.9181459566     0.8094768016     0.8092613010     9.9470589161    \n",
            "4                0.4399293363     0.4574956000     0.8974249363     0.9060650888     0.8065153011     0.8009922822     12.9794228077   \n",
            "5                0.3508658409     0.3248213828     0.6756871939     0.8621794872     0.7522211254     0.7679162073     15.4476397038   \n",
            "6                0.2565557361     0.6492792368     0.9058349729     0.9363905325     0.8173741362     0.8186328556     17.8846044540   \n",
            "7                0.6081970334     0.4346901476     1.0428872108     0.9169132150     0.8005923001     0.7965821389     20.3660781384   \n",
            "8                0.3714170456     0.6881191730     1.0595362186     0.8856015779     0.7601184600     0.7728776185     22.8007612228   \n",
            "9                0.2704993784     0.6695899367     0.9400893450     0.9181459566     0.7749259625     0.8004410143     25.7351243496   \n",
            "\n",
            "========ROUND 6========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.4209126234    \n",
            "1                0.1561801583    \n",
            "2                0.2667513192    \n",
            "3                0.2845916450    \n",
            "4                0.9166198373    \n",
            "5                0.8534470201    \n",
            "6                0.5008746982    \n",
            "7                0.9035971165    \n",
            "8                0.2061391920    \n",
            "9                0.4536224306    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.8446996212     1.6669369936     0.1777625680    \n",
            "1                1.6252232790     1.4546753168     0.1705479473    \n",
            "2                1.4360736609     1.1774274111     0.2586462796    \n",
            "3                1.0174033642     0.9420523047     0.0753510892    \n",
            "4                1.1774046421     1.1667591333     0.0106455078    \n",
            "5                0.8760530949     0.8742889762     0.0017641158    \n",
            "6                1.4070187807     1.4063051939     0.0007135824    \n",
            "7                1.3419470787     1.2406204939     0.1013265625    \n",
            "8                0.9846396446     0.8341744542     0.1504651755    \n",
            "9                1.0692187548     1.0329538584     0.0362648554    \n",
            "Counter({1: 2554, 0: 1502})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.6190481782     0.5796576142     1.1987057924     0.8316074951     0.7324777887     0.7579933848     2.4447417259    \n",
            "1                0.3698925078     0.2968737781     0.6667662859     0.8856015779     0.7749259625     0.7927232635     4.8979949951    \n",
            "2                0.3363764584     0.4749341905     0.8113106489     0.8745069034     0.7522211254     0.7535832415     7.3237833977    \n",
            "3                0.4275832474     0.5333611369     0.9609444141     0.8994082840     0.7877591313     0.7800441014     9.8212108612    \n",
            "4                0.1853121519     0.5281033516     0.7134155035     0.8552761341     0.7492596249     0.7668136714     12.6849405766   \n",
            "5                0.4071328938     0.5251066089     0.9322395325     0.8989151874     0.7453109576     0.7761852260     15.1047625542   \n",
            "6                0.6803374887     0.4436836243     1.1240210533     0.8880670611     0.7788746298     0.7811466373     17.5521221161   \n",
            "7                0.7524850965     0.5190727115     1.2715578079     0.8688362919     0.7364264561     0.7227122381     19.9643931389   \n",
            "8                0.6676475406     0.6971318126     1.3647793531     0.8929980276     0.7295162883     0.7475192944     22.7036352158   \n",
            "9                0.5818306804     0.6065312624     1.1883618832     0.9178994083     0.7690029615     0.7712238148     25.4752290249   \n",
            "\n",
            "========ROUND 7========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.2286267728    \n",
            "1                0.3050028086    \n",
            "2                0.3036042750    \n",
            "3                0.4608851969    \n",
            "4                0.2986190617    \n",
            "5                0.2942145765    \n",
            "6                0.4063124657    \n",
            "7                0.5831666589    \n",
            "8                0.5130932331    \n",
            "9                0.5481091142    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.8931368589     0.7822394371     0.1108973920    \n",
            "1                1.0165114403     0.9432000518     0.0733114108    \n",
            "2                1.2717193365     1.1882412434     0.0834781006    \n",
            "3                1.0411553383     1.0206745863     0.0204807483    \n",
            "4                0.9885320663     0.9739243388     0.0146077126    \n",
            "5                0.9233809710     0.9123392701     0.0110417018    \n",
            "6                1.4337586164     1.2166793346     0.2170792818    \n",
            "7                1.0522816181     0.9807631969     0.0715183988    \n",
            "8                1.2913721800     1.2626312971     0.0287409332    \n",
            "9                0.8544703126     0.8429084420     0.0115618734    \n",
            "Counter({1: 2594, 0: 1462})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.4430880845     0.5356457829     0.9787338972     0.8616863905     0.7334649556     0.7541345094     2.4563903809    \n",
            "1                0.8119845986     0.5449283719     1.3569129705     0.9060650888     0.7907206318     0.7866593164     4.8911135197    \n",
            "2                0.4764027894     0.6175205112     1.0939233303     0.8488658777     0.7393879566     0.7579933848     7.3882873058    \n",
            "3                0.7461648583     0.8095255494     1.5556904078     0.7879684418     0.6623889437     0.6543550165     10.3239266872   \n",
            "4                0.5188098550     0.4714255631     0.9902354479     0.9309664694     0.8065153011     0.7976846748     12.9663829803   \n",
            "5                0.3599351943     0.5367572308     0.8966923952     0.9149408284     0.7808489635     0.7844542448     15.4146320820   \n",
            "6                0.4441642463     0.6594755054     1.1036397219     0.9119822485     0.7709772952     0.7877618523     17.9105165005   \n",
            "7                0.6181434989     0.5816555023     1.1997990608     0.9003944773     0.7670286278     0.7646085998     20.3449914455   \n",
            "8                0.3626512289     0.4749368429     0.8375880718     0.8505917160     0.7354392892     0.7227122381     23.3694405556   \n",
            "9                0.4919354022     0.5761023164     1.0680377483     0.8994082840     0.7670286278     0.7866593164     25.8109502792   \n",
            "\n",
            "========ROUND 8========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.3015359938    \n",
            "1                0.2824691236    \n",
            "2                0.3444093466    \n",
            "3                0.2518629730    \n",
            "4                0.5237279534    \n",
            "5                0.2334216684    \n",
            "6                0.9662807584    \n",
            "7                0.3987984955    \n",
            "8                0.2464010715    \n",
            "9                0.8340978026    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.7870094180     0.6882553697     0.0987540483    \n",
            "1                1.3414522409     1.2079499960     0.1335022002    \n",
            "2                0.9843157530     0.9624845982     0.0218311530    \n",
            "3                1.0851062536     0.8922452331     0.1928610653    \n",
            "4                1.3526922464     1.3467164040     0.0059758592    \n",
            "5                0.9149176478     0.8571319580     0.0577857085    \n",
            "6                1.0690553188     0.9428737164     0.1261815578    \n",
            "7                1.2342391014     1.2309621572     0.0032768920    \n",
            "8                1.3375207186     1.0375562906     0.2999644279    \n",
            "9                1.2142186165     1.1753380299     0.0388805717    \n",
            "Counter({1: 2587, 0: 1469})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.4220395386     0.4757990837     0.8978385925     0.8959566075     0.7443237907     0.7557883131     2.4131650925    \n",
            "1                0.3944324255     0.5360736251     0.9305060506     0.9048323471     0.7561697927     0.7717750827     4.8429052830    \n",
            "2                0.7704124451     0.6300178766     1.4004303217     0.9218441815     0.7551826259     0.7888643881     7.2843201160    \n",
            "3                0.6058192253     0.4884881675     1.0943074226     0.8680966469     0.7423494571     0.7568908490     10.2017724514   \n",
            "4                0.9772741199     0.6034060121     1.5806801319     0.8454142012     0.7087857848     0.7232635061     12.6493706703   \n",
            "5                0.4844858944     0.8625610471     1.3470469713     0.8607001972     0.7433366239     0.7541345094     15.0936157703   \n",
            "6                0.3590416908     0.6784345508     1.0374763012     0.8952169625     0.7403751234     0.7469680265     17.5995967388   \n",
            "7                0.2915465534     0.5789791942     0.8705257177     0.9188856016     0.7769002962     0.7706725469     20.2990295887   \n",
            "8                0.4636464417     0.5250766873     0.9887231588     0.8348126233     0.7048371175     0.7442116869     23.0161585808   \n",
            "9                0.3879730701     0.5079546571     0.8959277272     0.9003944773     0.7522211254     0.7728776185     25.4601371288   \n",
            "\n",
            "========ROUND 9========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.3018729389    \n",
            "1                0.5492706895    \n",
            "2                0.2251482457    \n",
            "3                0.1815839857    \n",
            "4                0.1261046678    \n",
            "5                0.3097177446    \n",
            "6                1.2415635586    \n",
            "7                0.3400541246    \n",
            "8                0.3740793467    \n",
            "9                0.2352176160    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.1264549494     1.0845428705     0.0419121198    \n",
            "1                0.8891828060     0.8479481339     0.0412346572    \n",
            "2                0.8846746683     0.8559165001     0.0287581682    \n",
            "3                1.0314464569     1.0248228312     0.0066236183    \n",
            "4                1.4109977484     1.3572400808     0.0537576191    \n",
            "5                1.3046308756     1.2679744959     0.0366563909    \n",
            "6                0.8981646299     0.7705242038     0.1276404411    \n",
            "7                1.3263182640     1.2608450651     0.0654732436    \n",
            "8                0.9886146188     0.9814303517     0.0071842489    \n",
            "9                0.9843515754     0.9656364322     0.0187151488    \n",
            "Counter({1: 2597, 0: 1459})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.5253034830     0.5985298157     1.1238332987     0.8858481262     0.7423494571     0.7453142227     2.4331791401    \n",
            "1                0.4882297516     0.5071657300     0.9953954816     0.7970907298     0.6614017769     0.6841234840     4.8740835190    \n",
            "2                0.6195318103     0.5265979171     1.1461297274     0.8828895464     0.7314906219     0.7447629548     7.7538120747    \n",
            "3                0.4090369642     0.4869135916     0.8959505558     0.9149408284     0.7620927937     0.7574421169     10.3733925819   \n",
            "4                1.0014004707     0.5959072113     1.5973076820     0.8868343195     0.7275419546     0.7590959206     12.8020927906   \n",
            "5                0.7041743398     0.8208479881     1.5250222683     0.9065581854     0.7532082922     0.7574421169     15.2465667725   \n",
            "6                0.1991492510     0.5285064578     0.7276557088     0.9321992110     0.7660414610     0.7690187431     17.6990690231   \n",
            "7                0.4044478834     0.5728874803     0.9773353338     0.8920118343     0.7541954590     0.7138919515     20.7573173046   \n",
            "8                0.6646858454     0.6655197740     1.3302056789     0.8957100592     0.7334649556     0.7221609702     23.2009148598   \n",
            "9                0.8415277600     0.8730155826     1.7145433426     0.9003944773     0.7532082922     0.7447629548     25.6398530006   \n",
            "Target acc: 0.8462\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --data_dir ./data/ --task cross_people --test_envs 2 --dataset emg --algorithm diversify --latent_domain_num 20 --alpha1 0.5 --alpha 1.0 --lam 0.0 --local_epoch 10 --max_epoch 10 --lr 0.01 --output ./data/train_output/act/cross_people-emg-Diversify-2-20-0.5-1-0-1-150-0.01"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlhEX9u2XtZD",
        "outputId": "9546ef90-2ea5-48b2-f47b-9fdccc1c2cfa",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment:\n",
            "\tPython: 3.11.13\n",
            "\tPyTorch: 2.6.0+cu124\n",
            "\tTorchvision: 0.21.0+cu124\n",
            "\tCUDA: 12.4\n",
            "\tCUDNN: 90100\n",
            "\tNumPy: 1.23.5\n",
            "\tPIL: 11.2.1\n",
            "==========================================\n",
            "algorithm:diversify\n",
            "alpha:1.0\n",
            "alpha1:0.5\n",
            "batch_size:32\n",
            "beta1:0.5\n",
            "bottleneck:256\n",
            "checkpoint_freq:100\n",
            "classifier:linear\n",
            "data_file:\n",
            "dataset:emg\n",
            "data_dir:./data/\n",
            "dis_hidden:256\n",
            "gpu_id:0\n",
            "layer:bn\n",
            "lam:0.0\n",
            "latent_domain_num:20\n",
            "local_epoch:10\n",
            "lr:0.01\n",
            "lr_decay1:1.0\n",
            "lr_decay2:1.0\n",
            "max_epoch:10\n",
            "model_size:median\n",
            "N_WORKERS:4\n",
            "old:False\n",
            "seed:0\n",
            "task:cross_people\n",
            "test_envs:[2]\n",
            "output:./data/train_output/act/cross_people-emg-Diversify-2-20-0.5-1-0-1-150-0.01\n",
            "weight_decay:0.0005\n",
            "steps_per_epoch:10000000000\n",
            "select_position:{'emg': [0]}\n",
            "select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}\n",
            "hz_list:{'emg': 1000}\n",
            "act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}\n",
            "num_classes:6\n",
            "input_shape:(8, 1, 200)\n",
            "grid_size:10\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[INFO] Optimal K determined as 2 (Silhouette Score: 0.1752)\n",
            "Using automated latent_domain_num (K): 2\n",
            "\n",
            "========ROUND 0========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "0                0.5959904790    \n",
            "1                1.2368434668    \n",
            "2                0.8042653203    \n",
            "3                1.1943707466    \n",
            "4                0.4924794436    \n",
            "5                0.6770478487    \n",
            "6                0.5464643240    \n",
            "7                0.5983372331    \n",
            "8                1.1483589411    \n",
            "9                0.4852339327    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                0.7364766002     0.7359178662     0.0005587476    \n",
            "1                1.7868199348     1.7863699198     0.0004500229    \n",
            "2                0.5159156322     0.5153854489     0.0005301937    \n",
            "3                1.7507101297     1.7501804829     0.0005296929    \n",
            "4                1.1704849005     1.1699984074     0.0004864475    \n",
            "5                0.2628352940     0.2624378800     0.0003974127    \n",
            "6                1.4267026186     1.4263828993     0.0003197294    \n",
            "7                1.3786553144     1.3781864643     0.0004688770    \n",
            "8                1.1560822725     1.1556789875     0.0004033276    \n",
            "9                0.7918144464     0.7912233472     0.0005910956    \n",
            "Counter({2: 4169})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                1.5891168118     0.0011158196     1.5902326107     0.8167426241     0.7984644914     0.7308612440     2.5053105354    \n",
            "1                0.5565688014     0.0005202397     0.5570890307     0.8860638043     0.8694817658     0.7906698565     4.9989759922    \n",
            "2                0.6899872422     0.0004783916     0.6904656291     0.8332933557     0.8061420345     0.7278708134     7.4827032089    \n",
            "3                0.2396060377     0.0003631648     0.2399692088     0.9062125210     0.8809980806     0.8122009569     10.0436589718   \n",
            "4                0.1391269118     0.0004913792     0.1396182925     0.9074118494     0.8541266795     0.7781100478     12.9107179642   \n",
            "5                0.6327989101     0.0004742213     0.6332731247     0.9114895658     0.8704414587     0.7834928230     15.3983602524   \n",
            "6                0.8000335097     0.0004615910     0.8004950881     0.8642360278     0.8253358925     0.7763157895     17.8887627125   \n",
            "7                0.5528185368     0.0005115552     0.5533300638     0.9126888942     0.8666026871     0.8062200957     20.4228763580   \n",
            "8                0.3386259973     0.0004385940     0.3390645981     0.9182058047     0.8694817658     0.8014354067     23.2841808796   \n",
            "9                0.2757044435     0.0007140338     0.2764184773     0.9249220437     0.8790786948     0.8014354067     25.9609658718   \n",
            "\n",
            "========ROUND 1========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.4613600373    \n",
            "1                0.5086439848    \n",
            "2                0.2078965306    \n",
            "3                0.3984689713    \n",
            "4                0.5359356403    \n",
            "5                0.8972129822    \n",
            "6                0.4032560587    \n",
            "7                0.6188647151    \n",
            "8                0.6467554569    \n",
            "9                0.5010703802    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.5438421965     1.5433746576     0.0004674868    \n",
            "1                0.8286684752     0.8280606866     0.0006077912    \n",
            "2                0.9303600192     0.9297535419     0.0006064666    \n",
            "3                1.3876659870     1.3871138096     0.0005521725    \n",
            "4                0.6545087099     0.6540813446     0.0004273394    \n",
            "5                1.2864629030     1.2859009504     0.0005619149    \n",
            "6                1.8687249422     1.8684450388     0.0002799035    \n",
            "7                1.2640174627     1.2634831667     0.0005342561    \n",
            "8                1.3567885160     1.3561038971     0.0006846206    \n",
            "9                1.6287093163     1.6281131506     0.0005962094    \n",
            "Counter({2: 1221, 19: 451, 12: 337, 9: 299, 14: 289, 3: 198, 1: 183, 4: 173, 16: 131, 10: 122, 13: 120, 17: 110, 0: 96, 6: 95, 7: 92, 5: 78, 18: 57, 11: 48, 8: 44, 15: 25})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.4493037462     1.8230681419     2.2723717690     0.8690333413     0.8003838772     0.7069377990     2.4704279900    \n",
            "1                0.3048479855     1.5009604692     1.8058084249     0.8755097146     0.8061420345     0.7069377990     4.9610517025    \n",
            "2                1.1278134584     2.3326573372     3.4604706764     0.9071719837     0.8176583493     0.6973684211     7.4630990028    \n",
            "3                0.1902918816     1.8804495335     2.0707414150     0.8923003118     0.7975047985     0.6830143541     10.4150292873   \n",
            "4                0.4641048610     3.3360104561     3.8001153469     0.8966178940     0.7917466411     0.6949760766     12.9070112705   \n",
            "5                0.3592306972     1.1853038073     1.5445344448     0.9234828496     0.8166986564     0.7344497608     15.3760545254   \n",
            "6                0.6076002121     1.3565897942     1.9641900063     0.8747901175     0.7543186180     0.6770334928     17.8879413605   \n",
            "7                0.9043433070     2.4161982536     3.3205416203     0.8949388343     0.7994241843     0.6889952153     20.6687839031   \n",
            "8                0.4572008550     1.6959233284     2.1531240940     0.9122091629     0.8051823417     0.7075358852     23.4262232780   \n",
            "9                1.8593904972     1.4964768887     3.3558673859     0.9131686256     0.8003838772     0.6997607656     25.9057493210   \n",
            "\n",
            "========ROUND 2========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                1.5597753525    \n",
            "1                2.0893378258    \n",
            "2                2.8352982998    \n",
            "3                1.8572745323    \n",
            "4                2.4719707966    \n",
            "5                1.9193712473    \n",
            "6                1.8088060617    \n",
            "7                0.8419339657    \n",
            "8                0.8981580734    \n",
            "9                2.1767034531    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                2.7972612381     1.0412412882     1.7560199499    \n",
            "1                2.7215347290     0.8912834525     1.8302512169    \n",
            "2                3.0121626854     1.7276437283     1.2845190763    \n",
            "3                3.1859807968     1.7815748453     1.4044060707    \n",
            "4                2.5648789406     1.1946732998     1.3702057600    \n",
            "5                4.4769849777     2.3027389050     2.1742460728    \n",
            "6                3.1874327660     1.2227474451     1.9646854401    \n",
            "7                1.2460982800     0.8176013827     0.4284968674    \n",
            "8                2.4024078846     0.6512134671     1.7511943579    \n",
            "9                1.7598837614     0.7175201178     1.0423636436    \n",
            "Counter({2: 965, 19: 397, 12: 314, 9: 280, 13: 241, 3: 218, 14: 215, 1: 188, 15: 170, 6: 148, 4: 142, 17: 139, 16: 138, 7: 132, 0: 126, 10: 106, 5: 82, 18: 64, 8: 58, 11: 46})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.4003674984     1.9255191088     2.3258867264     0.9182058047     0.8109404990     0.7404306220     2.4705319405    \n",
            "1                0.2389672846     1.9736186266     2.2125859261     0.9134084912     0.8119001919     0.7212918660     4.9398543835    \n",
            "2                0.6005173326     1.7317652702     2.3322825432     0.8949388343     0.7917466411     0.7284688995     8.0733315945    \n",
            "3                0.4020056725     2.0559170246     2.4579226971     0.8925401775     0.7610364683     0.6860047847     10.5139043331   \n",
            "4                0.4908101857     2.6352789402     3.1260890961     0.7548572799     0.6525911708     0.5717703349     13.0057182312   \n",
            "5                0.2502438128     1.6920869350     1.9423307180     0.8980570880     0.7639155470     0.7045454545     15.4916234016   \n",
            "6                1.2838977575     1.9655007124     3.2493984699     0.8925401775     0.7543186180     0.6979665072     18.0600800514   \n",
            "7                0.7440191507     1.7712260485     2.5152451992     0.8827056848     0.7418426104     0.6686602871     20.9194905758   \n",
            "8                0.3158373833     1.4431504011     1.7589877844     0.9206044615     0.7840690979     0.6967703349     23.3809809685   \n",
            "9                0.5578827262     2.1773712635     2.7352540493     0.9244423123     0.7936660269     0.7027511962     25.8489587307   \n",
            "\n",
            "========ROUND 3========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                1.4211637974    \n",
            "1                1.7069599628    \n",
            "2                1.3576456308    \n",
            "3                1.4534497261    \n",
            "4                0.8273678422    \n",
            "5                1.6824281216    \n",
            "6                1.7539423704    \n",
            "7                2.1360983849    \n",
            "8                1.1465709209    \n",
            "9                1.5848274231    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                2.2006897926     1.0416172743     1.1590726376    \n",
            "1                2.7232766151     1.3277211189     1.3955556154    \n",
            "2                1.5739223957     0.9182285666     0.6556937695    \n",
            "3                2.1287178993     1.2424219847     0.8862959743    \n",
            "4                1.3268296719     0.7424086928     0.5844209194    \n",
            "5                3.8284959793     1.0407477617     2.7877480984    \n",
            "6                2.0910756588     0.9996159077     1.0914597511    \n",
            "7                2.3205935955     1.8876004219     0.4329931736    \n",
            "8                2.4794497490     1.4513331652     1.0281167030    \n",
            "9                2.4961051941     1.0855231285     1.4105819464    \n",
            "Counter({2: 869, 19: 341, 12: 310, 9: 293, 13: 237, 14: 209, 3: 208, 15: 207, 1: 176, 4: 164, 6: 159, 0: 157, 7: 156, 16: 150, 17: 139, 10: 101, 5: 83, 11: 74, 8: 72, 18: 64})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.1038384736     2.3717348576     2.4755733013     0.9006956105     0.7811900192     0.6907894737     2.5245697498    \n",
            "1                0.4045116603     1.9979951382     2.4025068283     0.8846246102     0.7754318618     0.6901913876     5.6302700043    \n",
            "2                0.0845828205     2.1174709797     2.2020537853     0.9026145359     0.7831094050     0.6949760766     8.1680724621    \n",
            "3                0.5183891058     1.8217879534     2.3401770592     0.9057327896     0.7975047985     0.6877990431     10.6636986732   \n",
            "4                0.2232791781     2.5310702324     2.7543494701     0.9158071480     0.7773512476     0.6800239234     13.1909101009   \n",
            "5                0.4093070030     2.6042299271     3.0135369301     0.9050131926     0.7811900192     0.6734449761     15.7500288486   \n",
            "6                1.4136495590     2.4079818726     3.8216314316     0.8946989686     0.7667946257     0.6854066986     18.7149386406   \n",
            "7                0.1895878166     1.3915522099     1.5811400414     0.9088510434     0.7658349328     0.6584928230     21.2103652954   \n",
            "8                0.2551972568     1.9158444405     2.1710417271     0.8999760134     0.7735124760     0.6800239234     23.7377939224   \n",
            "9                1.3637123108     2.8704292774     4.2341413498     0.8841448789     0.7399232246     0.6740430622     26.2354784012   \n",
            "\n",
            "========ROUND 4========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                2.0228927135    \n",
            "1                0.8343755007    \n",
            "2                1.3088575602    \n",
            "3                1.4469190836    \n",
            "4                1.7949776649    \n",
            "5                1.5751737356    \n",
            "6                1.1864901781    \n",
            "7                2.4123084545    \n",
            "8                0.2861214876    \n",
            "9                0.5350301266    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                2.7988350391     1.7349535227     1.0638815165    \n",
            "1                1.0896360874     0.7369498014     0.3526863456    \n",
            "2                2.0004255772     0.9715554118     1.0288702250    \n",
            "3                1.5463961363     1.2829203606     0.2634757459    \n",
            "4                2.2732100487     1.2196491957     1.0535607338    \n",
            "5                2.4299008846     1.4567255974     0.9731752872    \n",
            "6                1.2722567320     0.6971246004     0.5751321316    \n",
            "7                3.9243698120     1.2608553171     2.6635146141    \n",
            "8                3.5427594185     1.0834590197     2.4593002796    \n",
            "9                3.2861342430     0.7650086284     2.5211255550    \n",
            "Counter({2: 880, 19: 314, 12: 297, 9: 256, 13: 241, 15: 225, 3: 210, 14: 194, 1: 182, 7: 174, 6: 174, 0: 165, 16: 148, 4: 144, 17: 138, 10: 102, 11: 100, 8: 78, 5: 77, 18: 70})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.9233113527     2.0210371017     2.9443483353     0.9078915807     0.7821497121     0.7003588517     3.0850877762    \n",
            "1                0.3789830506     2.3093829155     2.6883659363     0.9062125210     0.7639155470     0.6854066986     5.5323336124    \n",
            "2                0.7758432031     2.2866339684     3.0624771118     0.9220436556     0.7667946257     0.7009569378     8.0422623158    \n",
            "3                0.6293413639     3.0119981766     3.6413395405     0.8841448789     0.7408829175     0.6543062201     10.5694665909   \n",
            "4                1.1493906975     2.5087244511     3.6581151485     0.9191652675     0.7744721689     0.6883971292     13.0531101227   \n",
            "5                1.8046286106     2.0832278728     3.8878564835     0.9162868793     0.7696737044     0.6848086124     16.0429949760   \n",
            "6                0.2894921601     1.7136416435     2.0031337738     0.9119692972     0.7552783109     0.6812200957     18.5558722019   \n",
            "7                1.5957599878     1.6143618822     3.2101218700     0.9141280883     0.7485604607     0.6919856459     21.0655066967   \n",
            "8                0.8296564817     2.5768933296     3.4065499306     0.9258815064     0.7658349328     0.6877990431     23.5644400120   \n",
            "9                0.6909512281     2.3487501144     3.0397014618     0.9273207004     0.7629558541     0.6889952153     26.4305374622   \n",
            "\n",
            "========ROUND 5========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                1.8259696960    \n",
            "1                2.3304791451    \n",
            "2                0.4639758468    \n",
            "3                1.2658867836    \n",
            "4                4.3469181061    \n",
            "5                1.4444333315    \n",
            "6                0.5925366879    \n",
            "7                1.1944906712    \n",
            "8                1.9998162985    \n",
            "9                2.8945679665    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                2.5154685974     1.1501537561     1.3653149605    \n",
            "1                3.9899172783     1.2938922644     2.6960248947    \n",
            "2                2.5828969479     1.6821732521     0.9007237554    \n",
            "3                6.2482218742     1.1894735098     5.0587482452    \n",
            "4                2.4713044167     1.4290314913     1.0422728062    \n",
            "5                1.5795267820     0.9874608517     0.5920659304    \n",
            "6                2.3494124413     0.9340350628     1.4153772593    \n",
            "7                2.9255948067     1.0711759329     1.8544188738    \n",
            "8                2.1359844208     1.1915973425     0.9443871379    \n",
            "9                1.6873503923     0.8974045515     0.7899458408    \n",
            "Counter({2: 856, 19: 291, 12: 280, 9: 242, 13: 232, 15: 223, 14: 199, 1: 198, 7: 191, 0: 190, 3: 190, 6: 172, 16: 155, 4: 146, 17: 128, 11: 116, 8: 98, 10: 93, 18: 90, 5: 79})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                1.4524552822     1.6734129190     3.1258683205     0.9206044615     0.7754318618     0.6895933014     2.6279850006    \n",
            "1                0.5262182951     2.1773486137     2.7035670280     0.9146078196     0.7648752399     0.6877990431     5.1229546070    \n",
            "2                0.7995780706     3.4247744083     4.2243523598     0.9198848645     0.7696737044     0.6848086124     7.6497919559    \n",
            "3                0.6530851722     1.7892470360     2.4423322678     0.9052530583     0.7571976967     0.6674641148     10.1500973701   \n",
            "4                0.4143775702     2.5727925301     2.9871702194     0.9191652675     0.7619961612     0.6901913876     13.1335711479   \n",
            "5                1.0523461103     2.1471562386     3.1995024681     0.9232429839     0.7677543186     0.6919856459     15.6387023926   \n",
            "6                1.2213249207     2.3701066971     3.5914316177     0.9246821780     0.7706333973     0.6782296651     18.1450080872   \n",
            "7                1.1716971397     2.6009156704     3.7726128101     0.9215639242     0.7351247601     0.6686602871     20.6308863163   \n",
            "8                0.8911449909     2.4879102707     3.3790552616     0.9407531782     0.7629558541     0.6943779904     23.4333593845   \n",
            "9                0.5815969706     2.5202307701     3.1018276215     0.9254017750     0.7667946257     0.6955741627     26.1906166077   \n",
            "\n",
            "========ROUND 6========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                1.2744885683    \n",
            "1                2.0335993767    \n",
            "2                0.9826416373    \n",
            "3                1.0530796051    \n",
            "4                1.9742031097    \n",
            "5                0.9298585057    \n",
            "6                1.8729796410    \n",
            "7                1.4054241180    \n",
            "8                0.6222940087    \n",
            "9                0.2601209879    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                2.1005139351     1.2478674650     0.8526465297    \n",
            "1                1.8396924734     1.5429404974     0.2967519760    \n",
            "2                2.8066990376     1.1553519964     1.6513470411    \n",
            "3                1.6501085758     1.0796691179     0.5704395175    \n",
            "4                2.1744070053     1.2830150127     0.8913918734    \n",
            "5                2.1359570026     1.5865812302     0.5493757725    \n",
            "6                3.1488370895     1.4436620474     1.7051749229    \n",
            "7                3.1284196377     1.7964986563     1.3319209814    \n",
            "8                1.8300145864     1.2707167864     0.5592978001    \n",
            "9                1.9669697285     0.7138683796     1.2531013489    \n",
            "Counter({2: 845, 12: 283, 19: 271, 9: 247, 15: 224, 13: 223, 0: 207, 1: 205, 7: 188, 3: 186, 14: 186, 6: 174, 16: 148, 4: 144, 17: 134, 11: 127, 8: 111, 18: 96, 10: 89, 5: 81})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.1889386177     2.3798074722     2.5687460899     0.9278004318     0.7850287908     0.6931818182     2.5098659992    \n",
            "1                0.8021147251     2.8231973648     3.6253120899     0.9393139842     0.7744721689     0.6901913876     4.9913871288    \n",
            "2                0.2113385797     2.1190907955     2.3304293156     0.9373950588     0.7744721689     0.6913875598     7.4966022968    \n",
            "3                1.5585638285     2.2887601852     3.8473238945     0.9513072679     0.7802303263     0.6961722488     10.5640423298   \n",
            "4                1.1636899710     2.4205505848     3.5842404366     0.9275605661     0.7696737044     0.6979665072     13.0500900745   \n",
            "5                0.5861219764     2.5856809616     3.1718029976     0.9477092828     0.7773512476     0.6985645933     15.5544805527   \n",
            "6                1.1807683706     2.9813547134     4.1621232033     0.9361957304     0.7677543186     0.6836124402     18.0493144989   \n",
            "7                0.2080027759     1.8969290257     2.1049318314     0.9282801631     0.7533589251     0.6794258373     20.7511084080   \n",
            "8                1.0931854248     2.3356592655     3.4288446903     0.9352362677     0.7456813820     0.6674641148     23.5336310863   \n",
            "9                0.5254369378     2.0402097702     2.5656466484     0.8745502519     0.7322456814     0.6537081340     26.0184836388   \n",
            "\n",
            "========ROUND 7========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.7415370345    \n",
            "1                1.1209675074    \n",
            "2                1.3195044994    \n",
            "3                1.9179782867    \n",
            "4                0.7434014678    \n",
            "5                0.4979198277    \n",
            "6                0.6478049159    \n",
            "7                2.1908326149    \n",
            "8                0.9314771295    \n",
            "9                0.6963675618    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.8451933861     0.7704007030     1.0747927427    \n",
            "1                2.5039181709     1.4126706123     1.0912475586    \n",
            "2                0.9912130833     0.7363536358     0.2548594475    \n",
            "3                1.5518515110     0.9644529819     0.5873985887    \n",
            "4                1.9963293076     0.9244293571     1.0719000101    \n",
            "5                2.1659598351     1.1084842682     1.0574756861    \n",
            "6                3.0192415714     0.8063812256     2.2128603458    \n",
            "7                2.0610103607     1.1444352865     0.9165751338    \n",
            "8                1.2243846655     1.0038238764     0.2205607444    \n",
            "9                2.7535114288     0.8826242089     1.8708872795    \n",
            "Counter({2: 829, 12: 280, 19: 261, 9: 246, 13: 227, 15: 218, 1: 215, 0: 215, 7: 188, 14: 186, 3: 184, 6: 180, 16: 153, 4: 138, 11: 134, 17: 126, 8: 106, 18: 101, 5: 97, 10: 85})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                1.1043457985     2.1364173889     3.2407631874     0.9244423123     0.7859884837     0.7003588517     2.4862933159    \n",
            "1                1.0017471313     2.8599317074     3.8616788387     0.9321180139     0.7725527831     0.6901913876     5.0002713203    \n",
            "2                1.3046603203     3.3771114349     4.6817717552     0.9460302231     0.7706333973     0.7021531100     8.0918397903    \n",
            "3                0.1013810709     1.7936513424     1.8950324059     0.9479491485     0.7629558541     0.6895933014     10.5687291622   \n",
            "4                0.4027736187     2.2942464352     2.6970200539     0.9508275366     0.7792706334     0.7003588517     13.0705654621   \n",
            "5                0.0194450282     2.1422884464     2.1617333889     0.9357159990     0.7831094050     0.6866028708     15.5631248951   \n",
            "6                0.4433648884     1.7735762596     2.2169411182     0.9397937155     0.7619961612     0.6674641148     18.1107966900   \n",
            "7                0.3692196608     1.6372817755     2.0065014362     0.9150875510     0.7533589251     0.6668660287     21.0817091465   \n",
            "8                0.5509370565     2.0263736248     2.5773105621     0.9486687455     0.7859884837     0.6913875598     23.5722985268   \n",
            "9                0.0904278308     1.9957097769     2.0861375332     0.9515471336     0.7869481766     0.7039473684     26.1464319229   \n",
            "\n",
            "========ROUND 8========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.9046131968    \n",
            "1                1.6805348396    \n",
            "2                1.4096852541    \n",
            "3                1.7943818569    \n",
            "4                0.4294606149    \n",
            "5                1.0570127964    \n",
            "6                1.0531589985    \n",
            "7                0.8612573743    \n",
            "8                1.6203204393    \n",
            "9                1.3908028603    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                4.6647419930     1.8038973808     2.8608446121    \n",
            "1                4.3352990150     1.3981131315     2.9371860027    \n",
            "2                3.2016677856     1.5303549767     1.6713128090    \n",
            "3                2.5244488716     1.1391521692     1.3852967024    \n",
            "4                1.7556704283     1.0492011309     0.7064692974    \n",
            "5                4.0145401955     1.5697437525     2.4447965622    \n",
            "6                2.0400753021     0.9938836694     1.0461916924    \n",
            "7                1.3023059368     0.7224413753     0.5798645020    \n",
            "8                2.2677659988     1.2761489153     0.9916170835    \n",
            "9                1.9530733824     1.8106274605     0.1424459070    \n",
            "Counter({2: 791, 12: 270, 19: 256, 13: 251, 9: 245, 15: 229, 0: 212, 1: 210, 3: 194, 14: 189, 6: 186, 7: 181, 16: 151, 4: 139, 11: 138, 8: 127, 17: 113, 5: 105, 18: 104, 10: 78})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.3115189373     3.2235791683     3.5350980759     0.9227632526     0.7687140115     0.7003588517     2.5057914257    \n",
            "1                1.4452081919     3.1335170269     4.5787253380     0.9467498201     0.7725527831     0.7009569378     5.6745743752    \n",
            "2                0.5053113699     2.1316986084     2.6370100975     0.9328376109     0.7552783109     0.6728468900     8.1773934364    \n",
            "3                0.3780617416     2.6531484127     3.0312101841     0.9498680739     0.7619961612     0.6824162679     10.6801402569   \n",
            "4                1.1647658348     2.5370824337     3.7018482685     0.9472295515     0.7600767754     0.6901913876     13.1837337017   \n",
            "5                0.6344197989     1.8079261780     2.4423460960     0.9323578796     0.7504798464     0.6800239234     15.6544387341   \n",
            "6                0.3357892036     2.0118691921     2.3476583958     0.9496282082     0.7735124760     0.6919856459     18.6514906883   \n",
            "7                0.1611707807     1.5781815052     1.7393522263     0.9522667306     0.7533589251     0.6752392344     21.1285610199   \n",
            "8                0.1876877695     1.9343022108     2.1219899654     0.9544255217     0.7648752399     0.6889952153     23.6320967674   \n",
            "9                0.5750828385     2.2490246296     2.8241074085     0.9498680739     0.7456813820     0.6854066986     26.1320822239   \n",
            "\n",
            "========ROUND 9========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                2.0603466034    \n",
            "1                1.8502646685    \n",
            "2                0.5778974891    \n",
            "3                1.1147074699    \n",
            "4                0.7786104083    \n",
            "5                0.9118105769    \n",
            "6                0.8948913217    \n",
            "7                1.3723120689    \n",
            "8                0.5973735452    \n",
            "9                0.9060028791    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.9295318127     0.9295215607     1.0000102520    \n",
            "1                3.2133970261     1.6565901041     1.5568070412    \n",
            "2                1.5172160864     1.3940531015     0.1231630370    \n",
            "3                0.9282333255     0.7036969662     0.2245363444    \n",
            "4                2.8436055183     1.1508961916     1.6927093267    \n",
            "5                1.9782699347     1.5083289146     0.4699409902    \n",
            "6                2.2034161091     1.4233980179     0.7800180912    \n",
            "7                2.5133676529     1.2868106365     1.2265568972    \n",
            "8                2.6632142067     1.3160482645     1.3471659422    \n",
            "9                3.6224901676     1.4207201004     2.2017700672    \n",
            "Counter({2: 768, 19: 276, 12: 271, 9: 249, 13: 246, 0: 225, 15: 216, 1: 201, 6: 198, 3: 184, 14: 183, 7: 178, 16: 153, 4: 145, 11: 143, 8: 130, 18: 118, 5: 108, 17: 103, 10: 74})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.7232956886     2.1971600056     2.9204556942     0.9378747901     0.7543186180     0.6979665072     3.0409200191    \n",
            "1                1.0076692104     2.5505163670     3.5581855774     0.9230031183     0.7341650672     0.6513157895     5.6733174324    \n",
            "2                0.1472508907     2.5841593742     2.7314102650     0.9460302231     0.7571976967     0.6764354067     8.1968927383    \n",
            "3                2.0956125259     2.3821237087     4.4777364731     0.9453106260     0.7715930902     0.6836124402     10.7483413219   \n",
            "4                0.7003104687     2.1599173546     2.8602278233     0.9433917006     0.7610364683     0.6872009569     13.2809133530   \n",
            "5                0.1598328948     1.7015653849     1.8613982201     0.9419525066     0.7523992322     0.6866028708     16.3445754051   \n",
            "6                0.3096792698     1.6748156548     1.9844949245     0.9421923723     0.7380038388     0.6776315789     18.8763515949   \n",
            "7                0.1316974610     3.0581867695     3.1898841858     0.9539457904     0.7552783109     0.6836124402     21.3966543674   \n",
            "8                0.8892033696     2.3436269760     3.2328302860     0.9114895658     0.7332053743     0.6608851675     23.8758530617   \n",
            "9                0.2278314382     2.6334993839     2.8613307476     0.9565843128     0.7552783109     0.6854066986     26.6628065109   \n",
            "Target acc: 0.8122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --data_dir ./data/ --task cross_people --test_envs 3 --dataset emg --algorithm diversify --latent_domain_num 5 --alpha1 5.0 --alpha 0.1 --lam 0.0 --local_epoch 10 --max_epoch 10 --lr 0.01 --output ./data/train_output/act/cross_people-emg-Diversify-3-5-5-0.1-0-5-30-0.01"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2f1YOdLXuGM",
        "outputId": "cd7173e3-1252-4580-c3a9-4ea36de2c8e4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment:\n",
            "\tPython: 3.11.13\n",
            "\tPyTorch: 2.6.0+cu124\n",
            "\tTorchvision: 0.21.0+cu124\n",
            "\tCUDA: 12.4\n",
            "\tCUDNN: 90100\n",
            "\tNumPy: 1.23.5\n",
            "\tPIL: 11.2.1\n",
            "==========================================\n",
            "algorithm:diversify\n",
            "alpha:0.1\n",
            "alpha1:5.0\n",
            "batch_size:32\n",
            "beta1:0.5\n",
            "bottleneck:256\n",
            "checkpoint_freq:100\n",
            "classifier:linear\n",
            "data_file:\n",
            "dataset:emg\n",
            "data_dir:./data/\n",
            "dis_hidden:256\n",
            "gpu_id:0\n",
            "layer:bn\n",
            "lam:0.0\n",
            "latent_domain_num:5\n",
            "local_epoch:10\n",
            "lr:0.01\n",
            "lr_decay1:1.0\n",
            "lr_decay2:1.0\n",
            "max_epoch:10\n",
            "model_size:median\n",
            "N_WORKERS:4\n",
            "old:False\n",
            "seed:0\n",
            "task:cross_people\n",
            "test_envs:[3]\n",
            "output:./data/train_output/act/cross_people-emg-Diversify-3-5-5-0.1-0-5-30-0.01\n",
            "weight_decay:0.0005\n",
            "steps_per_epoch:10000000000\n",
            "select_position:{'emg': [0]}\n",
            "select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}\n",
            "hz_list:{'emg': 1000}\n",
            "act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}\n",
            "num_classes:6\n",
            "input_shape:(8, 1, 200)\n",
            "grid_size:10\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[INFO] Optimal K determined as 2 (Silhouette Score: 0.1723)\n",
            "Using automated latent_domain_num (K): 2\n",
            "\n",
            "========ROUND 0========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "0                0.2875048220    \n",
            "1                0.7473749518    \n",
            "2                0.9085654616    \n",
            "3                0.8741014004    \n",
            "4                0.5510652065    \n",
            "5                0.3810003698    \n",
            "6                1.3601778746    \n",
            "7                0.2742419541    \n",
            "8                0.4187556505    \n",
            "9                0.9805910587    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.1304367781     1.1299117804     0.0005249555    \n",
            "1                1.2411183119     1.2406743765     0.0004438981    \n",
            "2                0.8788691163     0.8785503507     0.0003187920    \n",
            "3                0.7786270380     0.7781439424     0.0004830771    \n",
            "4                0.8862920403     0.8859062195     0.0003858460    \n",
            "5                1.1227806807     1.1225601435     0.0002205630    \n",
            "6                0.6814505458     0.6809948087     0.0004557401    \n",
            "7                1.0593390465     1.0588874817     0.0004515642    \n",
            "8                0.7657995820     0.7654034495     0.0003961298    \n",
            "9                0.8710014820     0.8705144525     0.0004870250    \n",
            "Counter({0: 1460, 4: 821, 2: 820, 3: 564, 1: 487})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.3089547455     0.5915274620     0.9004821777     0.8311657033     0.8073217726     0.7507383343     2.4784145355    \n",
            "1                1.0065778494     0.4300792515     1.4366570711     0.8473025048     0.8477842004     0.7832250443     5.0247235298    \n",
            "2                0.7753919959     0.5306860805     1.3060780764     0.8843930636     0.8439306358     0.7855877141     7.9451889992    \n",
            "3                0.7191180587     0.9226376414     1.6417557001     0.8487475915     0.8198458574     0.7649143532     10.4446866512   \n",
            "4                0.4470570385     0.4014461339     0.8485031724     0.9024566474     0.8757225434     0.8056704076     12.8816103935   \n",
            "5                0.2271450758     0.5569332838     0.7840783596     0.8954720617     0.8709055877     0.7613703485     15.3394892216   \n",
            "6                0.1187015995     0.4803833663     0.5990849733     0.9048651252     0.8795761079     0.7725930301     18.2015681267   \n",
            "7                0.5844061375     0.6036445498     1.1880507469     0.9067919075     0.8680154143     0.7702303603     20.8985857964   \n",
            "8                0.2412202209     0.4064609706     0.6476811767     0.9029383430     0.8400770713     0.7690490254     23.3596694469   \n",
            "9                0.6265671849     0.8286804557     1.4552476406     0.9193159923     0.8824662813     0.7997637330     25.7962617874   \n",
            "\n",
            "========ROUND 1========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.9828398824    \n",
            "1                1.1980363131    \n",
            "2                0.7388791442    \n",
            "3                0.8104971051    \n",
            "4                0.7546506524    \n",
            "5                0.6012930870    \n",
            "6                0.3692190945    \n",
            "7                0.7956611514    \n",
            "8                0.9320047498    \n",
            "9                0.3951279223    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.1934869289     0.5462269783     0.6472600102    \n",
            "1                1.8530936241     1.2412074804     0.6118862033    \n",
            "2                1.6167581081     0.8031427860     0.8136153817    \n",
            "3                1.3053925037     0.7784977555     0.5268948078    \n",
            "4                1.3159959316     0.9182274938     0.3977684975    \n",
            "5                1.3628315926     0.8397229314     0.5231087208    \n",
            "6                1.7805913687     1.1550490856     0.6255422831    \n",
            "7                2.2196886539     1.5412303209     0.6784582734    \n",
            "8                1.3115460873     0.9481713176     0.3633748293    \n",
            "9                1.8393123150     1.2026962042     0.6366160512    \n",
            "Counter({4: 1115, 0: 1014, 1: 709, 2: 690, 3: 624})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.4995329678     1.0447026491     1.5442355871     0.8959537572     0.8410404624     0.7838157118     2.4798383713    \n",
            "1                0.2066054493     0.7381153107     0.9447207451     0.9224470135     0.8631984586     0.7631423509     5.4932777882    \n",
            "2                0.2663636208     0.8698372245     1.1362009048     0.9135356455     0.8526011561     0.7979917307     7.9774518013    \n",
            "3                0.4494163692     0.4661301076     0.9155464768     0.9017341040     0.8458574181     0.7690490254     10.4853551388   \n",
            "4                0.6783336997     1.0040191412     1.6823527813     0.9173892100     0.8487475915     0.7832250443     12.9686133862   \n",
            "5                0.5533095002     1.2717607021     1.8250701427     0.9234104046     0.8680154143     0.7796810396     15.6049866676   \n",
            "6                0.3416012228     0.7672106624     1.1088118553     0.9022157996     0.8468208092     0.7607796810     18.5023322105   \n",
            "7                0.2309232950     0.9812304974     1.2121537924     0.8986030829     0.8362235067     0.7495569994     20.9862718582   \n",
            "8                0.3406581879     0.9247255921     1.2653837204     0.9164258189     0.8497109827     0.7767277023     23.4872965813   \n",
            "9                0.3172067106     1.1235266924     1.4407334328     0.9055876686     0.8574181118     0.7997637330     25.9704592228   \n",
            "\n",
            "========ROUND 2========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.6323839426    \n",
            "1                1.0597802401    \n",
            "2                1.1471773386    \n",
            "3                1.1818456650    \n",
            "4                0.7112829685    \n",
            "5                0.7163030505    \n",
            "6                0.5876559615    \n",
            "7                0.6399475336    \n",
            "8                0.8454654813    \n",
            "9                0.6865554452    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.6571643353     1.1402641535     0.5169001222    \n",
            "1                2.2879638672     1.3277943134     0.9601696134    \n",
            "2                1.8280749321     1.1786618233     0.6494130492    \n",
            "3                1.4330687523     0.8200664520     0.6130022407    \n",
            "4                1.9419367313     1.0077598095     0.9341769218    \n",
            "5                1.8950369358     1.1918647289     0.7031722665    \n",
            "6                1.9803906679     1.2194124460     0.7609782219    \n",
            "7                2.3124797344     1.4987182617     0.8137614727    \n",
            "8                2.0913696289     1.3787330389     0.7126364708    \n",
            "9                1.9742171764     1.3276534081     0.6465637684    \n",
            "Counter({4: 1620, 2: 695, 3: 655, 0: 647, 1: 535})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.4256617725     0.9964084625     1.4220702648     0.9147398844     0.8477842004     0.7731836976     2.9917035103    \n",
            "1                0.2246918529     1.1624587774     1.3871506453     0.8978805395     0.8545279383     0.7613703485     5.5643193722    \n",
            "2                0.7417598367     1.3618615866     2.1036214828     0.9149807322     0.8342967245     0.7554636740     8.0527970791    \n",
            "3                0.2421662658     0.9438379407     1.1860041618     0.9267822736     0.8651252408     0.7749556999     10.5203769207   \n",
            "4                0.3208377063     1.0640004873     1.3848382235     0.9349710983     0.8487475915     0.7767277023     12.9975826740   \n",
            "5                0.4669029415     1.1759200096     1.6428229809     0.9142581888     0.8420038536     0.7525103367     16.0018987656   \n",
            "6                0.5234560966     1.0843282938     1.6077843904     0.9195568401     0.8458574181     0.7590076787     18.4828321934   \n",
            "7                0.3246504962     1.0943543911     1.4190049171     0.8978805395     0.8236994220     0.7123449498     20.9803605080   \n",
            "8                0.2015963197     0.9942072034     1.1958035231     0.9340077071     0.8574181118     0.7720023627     23.4553103447   \n",
            "9                0.4730277061     1.0632295609     1.5362572670     0.9159441233     0.8564547206     0.7690490254     26.1885387897   \n",
            "\n",
            "========ROUND 3========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.7125845551    \n",
            "1                1.1238175631    \n",
            "2                1.0960854292    \n",
            "3                0.8474111557    \n",
            "4                1.1138435602    \n",
            "5                0.9351081848    \n",
            "6                0.8327152729    \n",
            "7                0.5607253313    \n",
            "8                0.9804027677    \n",
            "9                0.8999593854    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                2.1609823704     1.6328467131     0.5281356573    \n",
            "1                2.3056557178     1.5122166872     0.7934390903    \n",
            "2                1.7355580330     1.3443928957     0.3911651075    \n",
            "3                1.7747796774     1.3892360926     0.3855435550    \n",
            "4                1.9296669960     1.3522511721     0.5774158835    \n",
            "5                2.2046375275     1.3471022844     0.8575353622    \n",
            "6                1.7619110346     1.1400277615     0.6218832731    \n",
            "7                2.1577472687     1.4468270540     0.7109203339    \n",
            "8                1.7709907293     1.4574379921     0.3135527074    \n",
            "9                1.8276396990     1.4633294344     0.3643102944    \n",
            "Counter({4: 1635, 1: 730, 3: 713, 2: 562, 0: 512})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.4744404554     1.4658297300     1.9402701855     0.9296724470     0.8381502890     0.7625516834     2.7498052120    \n",
            "1                0.3878229856     1.1594835520     1.5473065376     0.9332851638     0.8429672447     0.7779090372     5.2605283260    \n",
            "2                0.1997899860     1.3985939026     1.5983839035     0.9364161850     0.8574181118     0.7708210278     7.7052943707    \n",
            "3                0.1557535082     1.2557663918     1.4115198851     0.9272639692     0.8371868979     0.7625516834     10.1647615433   \n",
            "4                0.1149829254     1.2078560591     1.3228390217     0.9349710983     0.8429672447     0.7873597165     13.2047996521   \n",
            "5                0.5766605735     1.2521344423     1.8287949562     0.9277456647     0.8506743738     0.7660956881     15.7350142002   \n",
            "6                0.5094203949     1.1579481363     1.6673685312     0.9296724470     0.8545279383     0.7731836976     18.2117118835   \n",
            "7                0.3756487072     1.3062621355     1.6819108725     0.9426782274     0.8506743738     0.7690490254     20.7021934986   \n",
            "8                0.5541294813     2.2264406681     2.7805700302     0.9429190751     0.8314065511     0.7743650325     23.1695187092   \n",
            "9                0.3422073126     1.4772516489     1.8194589615     0.9393063584     0.8526011561     0.7784997047     26.1570265293   \n",
            "\n",
            "========ROUND 4========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                1.2095040083    \n",
            "1                0.5344708562    \n",
            "2                0.6593627930    \n",
            "3                1.1797630787    \n",
            "4                0.7738006711    \n",
            "5                1.4472904205    \n",
            "6                0.8665699363    \n",
            "7                1.0730780363    \n",
            "8                1.1569536924    \n",
            "9                0.4732883871    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                2.2745833397     1.5600677729     0.7145156264    \n",
            "1                2.3529186249     1.7153635025     0.6375551820    \n",
            "2                1.9920120239     1.2205618620     0.7714501023    \n",
            "3                1.8183348179     1.3663191795     0.4520156384    \n",
            "4                2.5233061314     1.6457815170     0.8775245547    \n",
            "5                2.2291345596     1.3602017164     0.8689327240    \n",
            "6                2.6698558331     2.0088303089     0.6610254645    \n",
            "7                2.4060244560     1.5940624475     0.8119618893    \n",
            "8                2.4697005749     1.9356969595     0.5340036154    \n",
            "9                2.0182476044     1.3415378332     0.6767097116    \n",
            "Counter({4: 1615, 1: 799, 3: 662, 0: 541, 2: 535})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.0767797902     1.2287617922     1.3055416346     0.9308766859     0.8342967245     0.7554636740     2.4890983105    \n",
            "1                0.2560588419     1.0787273645     1.3347861767     0.9340077071     0.8487475915     0.7631423509     4.9654481411    \n",
            "2                0.0731257126     1.1780893803     1.2512151003     0.9419556840     0.8487475915     0.7702303603     7.4304864407    \n",
            "3                0.1518288702     1.1993670464     1.3511959314     0.9409922929     0.8420038536     0.7595983461     10.2981839180   \n",
            "4                0.5274246335     1.1912763119     1.7187008858     0.9465317919     0.8535645472     0.7643236858     13.0261735916   \n",
            "5                0.3956460953     1.2599023581     1.6555484533     0.9458092486     0.8439306358     0.7690490254     15.5643000603   \n",
            "6                0.2328172326     1.2713297606     1.5041470528     0.9426782274     0.8362235067     0.7684583579     18.0708210468   \n",
            "7                0.3582057059     1.1448107958     1.5030164719     0.9448458574     0.8458574181     0.7696396929     20.5561738014   \n",
            "8                0.1452201754     1.2446496487     1.3898698092     0.9501445087     0.8410404624     0.7578263438     23.6447203159   \n",
            "9                0.0960209072     1.2511496544     1.3471705914     0.9465317919     0.8487475915     0.7619610159     26.1210696697   \n",
            "\n",
            "========ROUND 5========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.6907038093    \n",
            "1                0.4958762825    \n",
            "2                0.9798681736    \n",
            "3                0.4171401560    \n",
            "4                0.8852564692    \n",
            "5                1.1298457384    \n",
            "6                0.6577810645    \n",
            "7                0.5458018780    \n",
            "8                0.9645647407    \n",
            "9                0.3353388011    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.6978323460     1.1750949621     0.5227373242    \n",
            "1                1.6769467592     1.4063676596     0.2705791295    \n",
            "2                2.0984823704     1.5548356771     0.5436466336    \n",
            "3                2.2323412895     1.8998993635     0.3324418068    \n",
            "4                1.7238637209     1.3934140205     0.3304496706    \n",
            "5                1.7507603168     1.4394923449     0.3112679422    \n",
            "6                2.3668720722     1.7208318710     0.6460402608    \n",
            "7                2.0552730560     1.3692289591     0.6860441566    \n",
            "8                1.6280969381     1.3779367208     0.2501602471    \n",
            "9                2.7931532860     1.6288248301     1.1643284559    \n",
            "Counter({4: 1403, 1: 794, 2: 686, 3: 671, 0: 598})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.1174441874     1.2775980234     1.3950421810     0.9402697495     0.8660886320     0.7660956881     2.5110356808    \n",
            "1                0.1779780984     1.3309680223     1.5089461803     0.9499036609     0.8641618497     0.7625516834     5.0099635124    \n",
            "2                0.3035265803     1.2032495737     1.5067760944     0.9246146435     0.8073217726     0.7253396338     7.7679715157    \n",
            "3                0.1971659809     1.1906222105     1.3877881765     0.9443641618     0.8391136802     0.7666863556     10.5077204704   \n",
            "4                0.2914548814     1.0519083738     1.3433632851     0.9108863198     0.8063583815     0.7188422918     12.9960291386   \n",
            "5                0.1632558107     1.1863752604     1.3496310711     0.9443641618     0.8333333333     0.7460129947     15.4654288292   \n",
            "6                0.3383013904     1.3102693558     1.6485707760     0.9383429672     0.8323699422     0.7336089781     17.9345827103   \n",
            "7                0.3053711355     1.2163369656     1.5217081308     0.9561657033     0.8593448940     0.7708210278     20.9543740749   \n",
            "8                0.3506685197     1.3333916664     1.6840602160     0.9489402697     0.8468208092     0.7578263438     23.5373408794   \n",
            "9                0.3195577264     1.3445969820     1.6641547680     0.9460500963     0.8381502890     0.7519196692     26.0540766716   \n",
            "\n",
            "========ROUND 6========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.8100143075    \n",
            "1                1.0323475599    \n",
            "2                1.0953665972    \n",
            "3                0.5667266250    \n",
            "4                0.8455139995    \n",
            "5                0.4439966679    \n",
            "6                0.3278603852    \n",
            "7                0.7938335538    \n",
            "8                0.3254355490    \n",
            "9                0.3782243431    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.7858546972     1.3171137571     0.4687409103    \n",
            "1                2.2711877823     1.6182745695     0.6529130936    \n",
            "2                2.1121826172     1.5586997271     0.5534830093    \n",
            "3                2.3384251595     1.5898565054     0.7485685349    \n",
            "4                2.0178864002     1.5927218199     0.4251645505    \n",
            "5                2.0758473873     1.4005719423     0.6752753854    \n",
            "6                2.0627233982     1.5268057585     0.5359176397    \n",
            "7                2.3009064198     1.6998282671     0.6010782123    \n",
            "8                2.6423962116     2.0615577698     0.5808385015    \n",
            "9                1.7846988440     1.4434078932     0.3412909508    \n",
            "Counter({4: 1193, 1: 805, 0: 797, 2: 714, 3: 643})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.3331772983     1.2033463717     1.5365236998     0.9559248555     0.8487475915     0.7619610159     2.4761531353    \n",
            "1                0.1697995216     1.1931818724     1.3629814386     0.9585741811     0.8554913295     0.7566450089     5.0553317070    \n",
            "2                0.1585359275     1.3535014391     1.5120373964     0.9527938343     0.8410404624     0.7542823390     7.9963257313    \n",
            "3                0.1115456223     1.3297389746     1.4412846565     0.9617052023     0.8516377649     0.7696396929     10.4878447056   \n",
            "4                0.0775959119     1.3036483526     1.3812443018     0.9527938343     0.8265895954     0.7625516834     12.9686176777   \n",
            "5                0.2292236686     1.4617781639     1.6910018921     0.9544797688     0.8410404624     0.7637330183     15.4584562778   \n",
            "6                0.1693928689     1.3201867342     1.4895795584     0.9559248555     0.8314065511     0.7542823390     18.3277001381   \n",
            "7                0.3666498661     1.2203634977     1.5870133638     0.9580924855     0.8362235067     0.7655050207     21.0082116127   \n",
            "8                0.2451332211     1.4493556023     1.6944887638     0.9573699422     0.8477842004     0.7424689900     23.4666891098   \n",
            "9                0.6416630149     1.5468430519     2.1885061264     0.9568882466     0.8333333333     0.7690490254     25.9460721016   \n",
            "\n",
            "========ROUND 7========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.5222510695    \n",
            "1                0.9689009786    \n",
            "2                0.8810970187    \n",
            "3                0.6156125665    \n",
            "4                0.6707029939    \n",
            "5                1.3332750797    \n",
            "6                0.5985218883    \n",
            "7                0.5458669066    \n",
            "8                0.6507384777    \n",
            "9                0.7691894174    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                1.9680520296     1.6469734907     0.3210785091    \n",
            "1                2.5922331810     2.0308778286     0.5613554716    \n",
            "2                1.8585016727     1.5635433197     0.2949583232    \n",
            "3                2.1137108803     1.8131309748     0.3005798757    \n",
            "4                1.9957878590     1.4232549667     0.5725329518    \n",
            "5                1.7686710358     1.2608101368     0.5078608394    \n",
            "6                2.6864688396     1.7354091406     0.9510596395    \n",
            "7                2.4043698311     1.5968279839     0.8075419068    \n",
            "8                1.8425755501     1.4810981750     0.3614773452    \n",
            "9                2.6480712891     1.7249256372     0.9231455922    \n",
            "Counter({4: 1079, 1: 981, 2: 813, 0: 691, 3: 588})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.2871596515     1.3886084557     1.6757681370     0.9592967245     0.8314065511     0.7601890136     2.4846961498    \n",
            "1                0.1914232969     1.2187241316     1.4101474285     0.9554431599     0.8371868979     0.7560543414     5.5082919598    \n",
            "2                0.2020109743     1.2903439999     1.4923549891     0.9554431599     0.8420038536     0.7395156527     8.0156860352    \n",
            "3                0.1715474129     1.1951578856     1.3667052984     0.9571290944     0.8400770713     0.7513290018     10.4988594055   \n",
            "4                0.2331152111     1.4195970297     1.6527122259     0.9564065511     0.8323699422     0.7253396338     12.9781370163   \n",
            "5                0.2302241921     1.3635979891     1.5938222408     0.9621868979     0.8314065511     0.7501476669     15.7718055248   \n",
            "6                0.1231448129     1.2038756609     1.3270205259     0.9578516378     0.8564547206     0.7489663320     18.5597798824   \n",
            "7                0.4298523664     1.0999363661     1.5297887325     0.9477360308     0.8217726397     0.7471943296     21.0248622894   \n",
            "8                0.1479625851     1.2957698107     1.4437323809     0.9431599229     0.8227360308     0.7206142942     23.5476427078   \n",
            "9                1.5796934366     1.1667941809     2.7464876175     0.9537572254     0.8294797688     0.7389249852     26.0366368294   \n",
            "\n",
            "========ROUND 8========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.8363616467    \n",
            "1                0.7783932090    \n",
            "2                0.5681751370    \n",
            "3                0.5894767046    \n",
            "4                0.7733795047    \n",
            "5                0.6336640716    \n",
            "6                0.7187148929    \n",
            "7                0.5610864758    \n",
            "8                1.2611874342    \n",
            "9                0.7237015367    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                2.0201022625     1.4552699327     0.5648323298    \n",
            "1                1.8264855146     1.5628643036     0.2636212409    \n",
            "2                1.9508390427     1.4828666449     0.4679723978    \n",
            "3                1.9012765884     1.5933694839     0.3079070747    \n",
            "4                2.1925871372     1.5395560265     0.6530311108    \n",
            "5                2.3518033028     1.4369549751     0.9148483276    \n",
            "6                2.6238503456     1.8746296167     0.7492207885    \n",
            "7                2.1940355301     1.6889814138     0.5050541759    \n",
            "8                2.1591711044     1.7994861603     0.3596848547    \n",
            "9                2.2582447529     1.4989446402     0.7593001723    \n",
            "Counter({2: 1077, 1: 967, 4: 906, 3: 705, 0: 497})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.6516057253     1.4302982092     2.0819039345     0.9624277457     0.8506743738     0.7531010041     3.0038940907    \n",
            "1                0.4883949459     1.5579668283     2.0463616848     0.9653179191     0.8477842004     0.7613703485     5.5048708916    \n",
            "2                0.1712397784     1.2751609087     1.4464006424     0.9653179191     0.8526011561     0.7471943296     7.9911670685    \n",
            "3                0.2364175171     1.2809711695     1.5173887014     0.9595375723     0.8448940270     0.7466036621     10.4933006763   \n",
            "4                0.2851535082     1.4582098722     1.7433633804     0.9701348748     0.8535645472     0.7560543414     13.3269996643   \n",
            "5                0.1754468530     1.3701863289     1.5456331968     0.9633911368     0.8497109827     0.7442409923     16.0958838463   \n",
            "6                0.3509122133     1.4563647509     1.8072769642     0.9629094412     0.8458574181     0.7542823390     18.7756025791   \n",
            "7                0.2866575718     1.1625925303     1.4492501020     0.9682080925     0.8448940270     0.7560543414     21.5619258881   \n",
            "8                0.3327610791     1.2733813524     1.6061424017     0.9761560694     0.8429672447     0.7560543414     24.1128361225   \n",
            "9                0.2247113436     1.3787881136     1.6034994125     0.9706165703     0.8420038536     0.7584170112     27.3682487011   \n",
            "\n",
            "========ROUND 9========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "0                0.9502045512    \n",
            "1                0.8398023248    \n",
            "2                0.6376204491    \n",
            "3                0.7009284496    \n",
            "4                0.7509720325    \n",
            "5                0.9868333936    \n",
            "6                0.3829196990    \n",
            "7                0.6236804724    \n",
            "8                0.6861436367    \n",
            "9                0.6329565644    \n",
            "====Latent domain characterization====\n",
            "epoch            total_loss       dis_loss         ent_loss        \n",
            "0                2.0300264359     1.4167604446     0.6132661104    \n",
            "1                2.2022540569     1.6378498077     0.5644043088    \n",
            "2                1.9787927866     1.5825051069     0.3962876499    \n",
            "3                1.9872626066     1.5115200281     0.4757425487    \n",
            "4                1.9736570120     1.6784433126     0.2952137291    \n",
            "5                2.3160953522     1.9446634054     0.3714318573    \n",
            "6                2.4158716202     1.7737962008     0.6420753002    \n",
            "7                2.0221447945     1.5522569418     0.4698877335    \n",
            "8                2.5235493183     1.6058931351     0.9176561236    \n",
            "9                1.8556461334     1.3284018040     0.5272443891    \n",
            "Counter({2: 1048, 1: 987, 4: 919, 3: 718, 0: 480})\n",
            "====Domain-invariant feature learning====\n",
            "epoch            class_loss       dis_loss         total_loss       train_acc        valid_acc        target_acc       total_cost_time \n",
            "0                0.8139223456     1.6504588127     2.4643812180     0.9544797688     0.8342967245     0.7436503249     2.5574271679    \n",
            "1                0.0826044232     1.1838697195     1.2664741278     0.9568882466     0.8391136802     0.7448316598     5.0469846725    \n",
            "2                0.1983963698     1.2525161505     1.4509124756     0.9600192678     0.8439306358     0.7371529829     7.5373978615    \n",
            "3                1.1119524240     1.4747538567     2.5867061615     0.9720616570     0.8448940270     0.7436503249     10.6601085663   \n",
            "4                0.5059476495     1.1986426115     1.7045903206     0.9636319846     0.8381502890     0.7501476669     13.3028366566   \n",
            "5                0.4400615990     1.2391954660     1.6792570353     0.9725433526     0.8410404624     0.7525103367     15.7947077751   \n",
            "6                0.3790327609     1.6194728613     1.9985055923     0.9691714836     0.8265895954     0.7531010041     18.2966661453   \n",
            "7                0.2997229993     1.2356023788     1.5353254080     0.9660404624     0.8227360308     0.7430596574     20.9001865387   \n",
            "8                0.5423092246     1.3104821444     1.8527913094     0.9641136802     0.8169556840     0.7412876551     23.8003363609   \n",
            "9                0.1537042707     1.1332646608     1.2869689465     0.9701348748     0.8381502890     0.7554636740     26.2576985359   \n",
            "Target acc: 0.7998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Target accuracies you got\n",
        "test_envs = [0, 1, 2, 3]\n",
        "accuracies = [68.37, 84.62, 81.22, 79.98]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(test_envs, accuracies, marker='o', linestyle='-', color='teal')\n",
        "plt.title('DIVERSIFY Target Accuracy per Test Environment', fontsize=16)\n",
        "plt.xlabel('Test Environment (Person Group)', fontsize=14)\n",
        "plt.ylabel('Target Accuracy (%)', fontsize=14)\n",
        "plt.xticks(test_envs)\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.ylim(60, 90)\n",
        "for i, acc in enumerate(accuracies):\n",
        "    plt.text(test_envs[i], acc+0.5, f'{acc:.2f}%', ha='center', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "ytmnQnCUlUmN",
        "outputId": "8cc4a8c2-c8e0-444e-89d0-85593380a6bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py \\\n",
        "  --data_dir ./data/ \\\n",
        "  --task cross_people \\\n",
        "  --test_envs 1 \\\n",
        "  --dataset emg \\\n",
        "  --algorithm diversify \\\n",
        "  --latent_domain_num 3 \\\n",
        "  --alpha1 0.01 \\\n",
        "  --alpha 2.0 \\\n",
        "  --lam 0.1 \\\n",
        "  --local_epoch 30 \\\n",
        "  --max_epoch 35 \\\n",
        "  --lr 0.003 \\\n",
        "  --model_size transformer \\\n",
        "  --output ./data/train_output/emg_best_try_plus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIg8UtxuJH7_",
        "outputId": "3fb9d5bc-e8fa-4d95-d933-4a4ef4ce2dc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment:\n",
            "\tPython: 3.11.13\n",
            "\tPyTorch: 2.6.0+cu124\n",
            "\tTorchvision: 0.21.0+cu124\n",
            "\tCUDA: 12.4\n",
            "\tCUDNN: 90100\n",
            "\tNumPy: 1.23.5\n",
            "\tPIL: 11.2.1\n",
            "==========================================\n",
            "algorithm:diversify\n",
            "alpha:2.0\n",
            "alpha1:0.01\n",
            "batch_size:32\n",
            "beta1:0.5\n",
            "bottleneck:256\n",
            "checkpoint_freq:100\n",
            "classifier:linear\n",
            "data_file:\n",
            "dataset:emg\n",
            "data_dir:./data/\n",
            "dis_hidden:256\n",
            "gpu_id:0\n",
            "layer:bn\n",
            "lam:0.1\n",
            "latent_domain_num:3\n",
            "local_epoch:30\n",
            "lr:0.003\n",
            "lr_decay1:1.0\n",
            "lr_decay2:1.0\n",
            "max_epoch:35\n",
            "model_size:transformer\n",
            "N_WORKERS:4\n",
            "old:False\n",
            "seed:0\n",
            "task:cross_people\n",
            "test_envs:[1]\n",
            "output:./data/train_output/emg_best_try_plus\n",
            "weight_decay:0.0005\n",
            "steps_per_epoch:10000000000\n",
            "select_position:{'emg': [0]}\n",
            "select_channel:{'emg': array([0, 1, 2, 3, 4, 5, 6, 7])}\n",
            "hz_list:{'emg': 1000}\n",
            "act_people:{'emg': [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32, 33, 34, 35]]}\n",
            "num_classes:6\n",
            "input_shape:(8, 1, 200)\n",
            "grid_size:10\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[INFO] Optimal K determined as 2 (Silhouette Score: 0.4636)\n",
            "Using automated latent_domain_num (K): 2\n",
            "\n",
            "========ROUND 0========\n",
            "====Feature update====\n",
            "epoch            class_loss      \n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "0                0.8872755170    \n",
            "1                0.8639214039    \n",
            "2                0.4902851582    \n",
            "3                0.3579983711    \n",
            "4                0.8511015773    \n",
            "5                0.6975054145    \n",
            "6                0.5949060321    \n",
            "7                0.5285410285    \n",
            "8                0.2934125364    \n",
            "9                0.4137970507    \n",
            "10               0.3224455416    \n",
            "11               0.7793714404    \n",
            "12               0.1016606316    \n",
            "13               0.1964163780    \n",
            "14               0.1724403650    \n",
            "15               0.2227525562    \n",
            "16               0.2483134419    \n",
            "17               0.2244874835    \n",
            "Traceback (most recent call last):\n",
            "  File \"/content/repo/diversify/train.py\", line 124, in <module>\n",
            "    main(args)\n",
            "  File \"/content/repo/diversify/train.py\", line 78, in main\n",
            "    loss_result_dict = algorithm.update_a(data, opta)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/repo/diversify/alg/algs/diversify.py\", line 142, in update_a\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
            "    _engine_run_backward(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
            "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    }
  ]
}